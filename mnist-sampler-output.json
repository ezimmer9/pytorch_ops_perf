{
    "name": "Some Default",
    "origin": "",
    "cpu_info": {
        "Architecture": "x86_64",
        "CPU op-mode(s)": "32-bit, 64-bit",
        "Byte Order": "Little Endian",
        "Address sizes": "46 bits physical, 48 bits virtual",
        "CPU(s)": "64",
        "On-line CPU(s) list": "0-63",
        "Thread(s) per core": "2",
        "Core(s) per socket": "16",
        "Socket(s)": "2",
        "NUMA node(s)": "2",
        "Vendor ID": "GenuineIntel",
        "CPU family": "6",
        "Model": "85",
        "Model name": "Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz",
        "Stepping": "7",
        "CPU MHz": "3772.875",
        "CPU max MHz": "3900.0000",
        "CPU min MHz": "1200.0000",
        "BogoMIPS": "5800.00",
        "Virtualization": "VT-x",
        "L1d cache": "1 MiB",
        "L1i cache": "1 MiB",
        "L2 cache": "32 MiB",
        "L3 cache": "44 MiB",
        "NUMA node0 CPU(s)": "0-15,32-47",
        "NUMA node1 CPU(s)": "16-31,48-63",
        "Vulnerability Itlb multihit": "KVM",
        "Vulnerability L1tf": "Not affected",
        "Vulnerability Mds": "Not affected",
        "Vulnerability Meltdown": "Not affected",
        "Vulnerability Spec store bypass": "Mitigation; Speculative Store Bypass disabled via prctl and seccomp",
        "Vulnerability Spectre v1": "Mitigation; usercopy/swapgs barriers and __user pointer sanitization",
        "Vulnerability Spectre v2": "Mitigation; Enhanced IBRS, IBPB conditional, RSB filling",
        "Vulnerability Srbds": "Not affected",
        "Vulnerability Tsx async abort": "Mitigation; TSX disabled",
        "Flags": "fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 cdp_l3 invpcid_single intel_ppin ssbd mba ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm mpx rdt_a avx512f avx512dq rdseed adx smap clflushopt clwb intel_pt avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts hwp hwp_act_window hwp_epp hwp_pkg_req pku ospke avx512_vnni md_clear flush_l1d arch_capabilities"
    },
    "meta": {},
    "layers": [
        {
            "name": "Net/Conv2d/op-1",
            "optype": "aten::conv2d",
            "params": {
                "dilation": [
                    1,
                    1
                ],
                "groups": 1,
                "input_size": [
                    64,
                    1,
                    28,
                    28
                ],
                "padding": [
                    0,
                    0
                ],
                "stride": [
                    1,
                    1
                ],
                "weight_size": [
                    32,
                    1,
                    3,
                    3
                ]
            },
            "inputs": [
                "t-2",
                "t-4",
                "t-6"
            ],
            "outputs": [
                "t-7"
            ],
            "stats": {
                "cycles": 4673675.0,
                "instructions": 4352964.0,
                "l1_read": 1882578.0,
                "l1_write": 630443.0,
                "llc_access": 293558.0,
                "microseconds": 1712,
                "flops": 24920064.0
            },
            "meta": {},
            "args": [
                [
                    1,
                    1
                ],
                [
                    0,
                    0
                ],
                [
                    1,
                    1
                ],
                1
            ],
            "runtime": {
                "duration": 1712,
                "start": 251415,
                "end": 253127
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 52, in train\n    output = model(data)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"examples/mnist/main.py\", line 29, in forward\n    x = self.conv1(x)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 446, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 442, in _conv_forward\n    return F.conv2d(input, weight, bias, self.stride,\n"
            ]
        },
        {
            "name": "Net/op-2",
            "optype": "aten::relu",
            "params": {},
            "inputs": [
                "t-7"
            ],
            "outputs": [
                "t-8"
            ],
            "stats": {
                "cycles": 2135508.0,
                "instructions": 1438204.0,
                "l1_read": 485027.0,
                "l1_write": 286215.0,
                "llc_access": 178835.0,
                "microseconds": 633,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 633,
                "start": 253197,
                "end": 253830
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 52, in train\n    output = model(data)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"examples/mnist/main.py\", line 30, in forward\n    x = F.relu(x)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/functional.py\", line 1299, in relu\n    result = torch.relu(input)\n"
            ]
        },
        {
            "name": "Net/Conv2d/op-3",
            "optype": "aten::conv2d",
            "params": {
                "dilation": [
                    1,
                    1
                ],
                "groups": 1,
                "input_size": [
                    64,
                    32,
                    26,
                    26
                ],
                "padding": [
                    0,
                    0
                ],
                "stride": [
                    1,
                    1
                ],
                "weight_size": [
                    64,
                    32,
                    3,
                    3
                ]
            },
            "inputs": [
                "t-8",
                "t-10",
                "t-12"
            ],
            "outputs": [
                "t-13"
            ],
            "stats": {
                "cycles": 34496489.0,
                "instructions": 51712162.0,
                "l1_read": 46547472.0,
                "l1_write": 1444520.0,
                "llc_access": 736391.0,
                "microseconds": 10652,
                "flops": 1358954496.0
            },
            "meta": {},
            "args": [
                [
                    1,
                    1
                ],
                [
                    0,
                    0
                ],
                [
                    1,
                    1
                ],
                1
            ],
            "runtime": {
                "duration": 10652,
                "start": 253968,
                "end": 264620
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 52, in train\n    output = model(data)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"examples/mnist/main.py\", line 31, in forward\n    x = self.conv2(x)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 446, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 442, in _conv_forward\n    return F.conv2d(input, weight, bias, self.stride,\n"
            ]
        },
        {
            "name": "Net/op-4",
            "optype": "aten::relu",
            "params": {},
            "inputs": [
                "t-13"
            ],
            "outputs": [
                "t-14"
            ],
            "stats": {
                "cycles": 4534264.0,
                "instructions": 1927972.0,
                "l1_read": 668268.0,
                "l1_write": 408468.0,
                "llc_access": 301129.0,
                "microseconds": 1359,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 1359,
                "start": 264686,
                "end": 266045
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 52, in train\n    output = model(data)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"examples/mnist/main.py\", line 32, in forward\n    x = F.relu(x)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/functional.py\", line 1299, in relu\n    result = torch.relu(input)\n"
            ]
        },
        {
            "name": "Net/op-5",
            "optype": "aten::max_pool2d",
            "params": {},
            "inputs": [
                "t-14"
            ],
            "outputs": [
                "t-15"
            ],
            "stats": {
                "cycles": 24358884.0,
                "instructions": 65507924.0,
                "l1_read": 15050568.0,
                "l1_write": 2467765.0,
                "llc_access": 264558.0,
                "microseconds": 6721,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                [
                    2,
                    2
                ],
                [],
                [
                    0,
                    0
                ],
                [
                    1,
                    1
                ],
                false
            ],
            "runtime": {
                "duration": 6721,
                "start": 266416,
                "end": 273137
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 52, in train\n    output = model(data)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"examples/mnist/main.py\", line 33, in forward\n    x = F.max_pool2d(x, 2)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_jit_internal.py\", line 422, in fn\n    return if_false(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/functional.py\", line 719, in _max_pool2d\n    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
            ]
        },
        {
            "name": "Net/Dropout/op-6",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-15"
            ],
            "outputs": [
                "t-16"
            ],
            "stats": {
                "cycles": 6155800.0,
                "instructions": 5960920.0,
                "l1_read": 1380928.0,
                "l1_write": 819762.0,
                "llc_access": 321817.0,
                "microseconds": 1750,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                0.25,
                true
            ],
            "runtime": {
                "duration": 1750,
                "start": 273373,
                "end": 275123
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 52, in train\n    output = model(data)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"examples/mnist/main.py\", line 34, in forward\n    x = self.dropout1(x)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "Net/op-7",
            "optype": "aten::flatten",
            "params": {},
            "inputs": [
                "t-16"
            ],
            "outputs": [
                "t-17"
            ],
            "stats": {
                "cycles": 176120.0,
                "instructions": 218528.0,
                "l1_read": 65512.0,
                "l1_write": 33343.0,
                "llc_access": 2389.0,
                "microseconds": 50,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                1,
                -1
            ],
            "runtime": {
                "duration": 50,
                "start": 275203,
                "end": 275253
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 52, in train\n    output = model(data)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"examples/mnist/main.py\", line 35, in forward\n    x = torch.flatten(x, 1)\n"
            ]
        },
        {
            "name": "Net/Linear/op-8",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-17",
                "t-19",
                "t-21"
            ],
            "outputs": [
                "t-22"
            ],
            "stats": {
                "cycles": 8492672.0,
                "instructions": 11583024.0,
                "l1_read": 4204528.0,
                "l1_write": 524936.0,
                "llc_access": 190290.0,
                "microseconds": 2996,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 2996,
                "start": 275437,
                "end": 278433
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 52, in train\n    output = model(data)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"examples/mnist/main.py\", line 36, in forward\n    x = self.fc1(x)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "Net/op-9",
            "optype": "aten::relu",
            "params": {},
            "inputs": [
                "t-22"
            ],
            "outputs": [
                "t-23"
            ],
            "stats": {
                "cycles": 486216.0,
                "instructions": 747776.0,
                "l1_read": 226400.0,
                "l1_write": 113925.0,
                "llc_access": 5357.0,
                "microseconds": 177,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 177,
                "start": 278517,
                "end": 278694
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 52, in train\n    output = model(data)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"examples/mnist/main.py\", line 37, in forward\n    x = F.relu(x)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/functional.py\", line 1299, in relu\n    result = torch.relu(input)\n"
            ]
        },
        {
            "name": "Net/Dropout/op-10",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-23"
            ],
            "outputs": [
                "t-24"
            ],
            "stats": {
                "cycles": 1976368.0,
                "instructions": 3496352.0,
                "l1_read": 1050728.0,
                "l1_write": 527123.0,
                "llc_access": 11102.0,
                "microseconds": 699,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                0.5,
                true
            ],
            "runtime": {
                "duration": 699,
                "start": 278792,
                "end": 279491
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 52, in train\n    output = model(data)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"examples/mnist/main.py\", line 38, in forward\n    x = self.dropout2(x)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "Net/Linear/op-11",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-24",
                "t-26",
                "t-28"
            ],
            "outputs": [
                "t-29"
            ],
            "stats": {
                "cycles": 1621920.0,
                "instructions": 2855888.0,
                "l1_read": 868384.0,
                "l1_write": 428172.0,
                "llc_access": 7950.0,
                "microseconds": 544,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 544,
                "start": 279572,
                "end": 280116
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 52, in train\n    output = model(data)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"examples/mnist/main.py\", line 39, in forward\n    x = self.fc2(x)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "Net/op-12",
            "optype": "aten::log_softmax",
            "params": {},
            "inputs": [
                "t-29"
            ],
            "outputs": [
                "t-30"
            ],
            "stats": {
                "cycles": 210056.0,
                "instructions": 277344.0,
                "l1_read": 83512.0,
                "l1_write": 41905.0,
                "llc_access": 1726.0,
                "microseconds": 76,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                1
            ],
            "runtime": {
                "duration": 76,
                "start": 280194,
                "end": 280270
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 52, in train\n    output = model(data)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"examples/mnist/main.py\", line 40, in forward\n    output = F.log_softmax(x, dim=1)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/functional.py\", line 1769, in log_softmax\n    ret = input.log_softmax(dim)\n"
            ]
        },
        {
            "name": "op-13",
            "optype": "aten::nll_loss_nd",
            "params": {},
            "inputs": [
                "t-30",
                "t-32"
            ],
            "outputs": [
                "t-33"
            ],
            "stats": {
                "cycles": 250360.0,
                "instructions": 368992.0,
                "l1_read": 111584.0,
                "l1_write": 56731.0,
                "llc_access": 1267.0,
                "microseconds": 96,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                1,
                -100
            ],
            "runtime": {
                "duration": 96,
                "start": 280332,
                "end": 280428
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 53, in train\n    loss = F.nll_loss(output, target)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/nn/functional.py\", line 2532, in nll_loss\n    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)\n"
            ]
        },
        {
            "name": "op-14",
            "optype": "aten::ones_like",
            "params": {},
            "inputs": [
                "t-33"
            ],
            "outputs": [
                "t-34"
            ],
            "stats": {
                "cycles": 478288.0,
                "instructions": 736832.0,
                "l1_read": 222352.0,
                "l1_write": 111599.0,
                "llc_access": 3897.0,
                "microseconds": 152,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                6,
                0,
                false,
                1
            ],
            "runtime": {
                "duration": 152,
                "start": 280837,
                "end": 280989
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 150, in backward\n    grad_tensors_ = _make_grads(tensors, grad_tensors_)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 52, in _make_grads\n    new_grads.append(torch.ones_like(out, memory_format=torch.preserve_format))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: NllLossBackward0/NllLossBackward0/op-15",
            "optype": "aten::nll_loss_backward",
            "params": {},
            "inputs": [
                "t-34",
                "t-30",
                "t-32",
                "t-36"
            ],
            "outputs": [
                "t-37"
            ],
            "stats": {
                "cycles": 153712.0,
                "instructions": 221808.0,
                "l1_read": 67216.0,
                "l1_write": 33585.0,
                "llc_access": 1048.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                1,
                -100
            ],
            "runtime": {
                "duration": 43,
                "start": 281158,
                "end": 281201
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: LogSoftmaxBackward0/LogSoftmaxBackward0/op-16",
            "optype": "aten::_log_softmax_backward_data",
            "params": {},
            "inputs": [
                "t-37",
                "t-39",
                "t-29"
            ],
            "outputs": [
                "t-40"
            ],
            "stats": {
                "cycles": 48256.0,
                "instructions": 23840.0,
                "l1_read": 7976.0,
                "l1_write": 3648.0,
                "llc_access": 614.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 281312,
                "end": 281324
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-17",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-42"
            ],
            "outputs": [
                "t-43"
            ],
            "stats": {
                "cycles": 256544.0,
                "instructions": 440576.0,
                "l1_read": 133184.0,
                "l1_write": 67263.0,
                "llc_access": 1158.0,
                "microseconds": 75,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 75,
                "start": 281437,
                "end": 281512
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-18",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    64,
                    10
                ],
                "mat2_size": [
                    10,
                    128
                ]
            },
            "inputs": [
                "t-40",
                "t-43"
            ],
            "outputs": [
                "t-44"
            ],
            "stats": {
                "cycles": 419072.0,
                "instructions": 660352.0,
                "l1_read": 199376.0,
                "l1_write": 98922.0,
                "llc_access": 2874.0,
                "microseconds": 123,
                "flops": 163840.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 123,
                "start": 281554,
                "end": 281677
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-19",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-40"
            ],
            "outputs": [
                "t-45"
            ],
            "stats": {
                "cycles": 297568.0,
                "instructions": 443440.0,
                "l1_read": 134024.0,
                "l1_write": 67603.0,
                "llc_access": 1725.0,
                "microseconds": 128,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 128,
                "start": 281724,
                "end": 281852
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-20",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    10,
                    64
                ],
                "mat2_size": [
                    64,
                    128
                ]
            },
            "inputs": [
                "t-45",
                "t-24"
            ],
            "outputs": [
                "t-46"
            ],
            "stats": {
                "cycles": 273000.0,
                "instructions": 446032.0,
                "l1_read": 135992.0,
                "l1_write": 66117.0,
                "llc_access": 2101.0,
                "microseconds": 81,
                "flops": 163840.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 81,
                "start": 281893,
                "end": 281974
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-21",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-46"
            ],
            "outputs": [
                "t-47"
            ],
            "stats": {
                "cycles": 249064.0,
                "instructions": 440352.0,
                "l1_read": 132992.0,
                "l1_write": 67209.0,
                "llc_access": 879.0,
                "microseconds": 78,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 78,
                "start": 282021,
                "end": 282099
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-22",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-40"
            ],
            "outputs": [
                "t-48"
            ],
            "stats": {
                "cycles": 172848.0,
                "instructions": 225568.0,
                "l1_read": 68056.0,
                "l1_write": 34446.0,
                "llc_access": 1801.0,
                "microseconds": 51,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 51,
                "start": 282142,
                "end": 282193
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-23",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-48"
            ],
            "outputs": [
                "t-49"
            ],
            "stats": {
                "cycles": 16232.0,
                "instructions": 6544.0,
                "l1_read": 2040.0,
                "l1_write": 1175.0,
                "llc_access": 306.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                [
                    10
                ]
            ],
            "runtime": {
                "duration": 4,
                "start": 282248,
                "end": 282252
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-24",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-51",
                "t-49"
            ],
            "outputs": [
                "t-52"
            ],
            "stats": {
                "cycles": 28016.0,
                "instructions": 8144.0,
                "l1_read": 2568.0,
                "l1_write": 1403.0,
                "llc_access": 611.0,
                "microseconds": 7,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                1
            ],
            "runtime": {
                "duration": 7,
                "start": 282391,
                "end": 282398
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-25",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-47"
            ],
            "outputs": [
                "t-53"
            ],
            "stats": {
                "cycles": 242632.0,
                "instructions": 440048.0,
                "l1_read": 133016.0,
                "l1_write": 67154.0,
                "llc_access": 710.0,
                "microseconds": 84,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 84,
                "start": 282520,
                "end": 282604
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-26",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-55",
                "t-53"
            ],
            "outputs": [
                "t-56"
            ],
            "stats": {
                "cycles": 16376.0,
                "instructions": 8848.0,
                "l1_read": 2936.0,
                "l1_write": 1551.0,
                "llc_access": 362.0,
                "microseconds": 3,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                1
            ],
            "runtime": {
                "duration": 3,
                "start": 282737,
                "end": 282740
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: MulBackward0/MulBackward0/op-27",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    64,
                    128
                ]
            },
            "inputs": [
                "t-44",
                "t-58"
            ],
            "outputs": [
                "t-59"
            ],
            "stats": {
                "cycles": 34688.0,
                "instructions": 13264.0,
                "l1_read": 4704.0,
                "l1_write": 2601.0,
                "llc_access": 1803.0,
                "microseconds": 9,
                "flops": 8192.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 9,
                "start": 282859,
                "end": 282868
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: ReluBackward0/ReluBackward0/op-28",
            "optype": "aten::threshold_backward",
            "params": {},
            "inputs": [
                "t-59",
                "t-61"
            ],
            "outputs": [
                "t-62"
            ],
            "stats": {
                "cycles": 39280.0,
                "instructions": 17568.0,
                "l1_read": 6832.0,
                "l1_write": 2640.0,
                "llc_access": 1136.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                0
            ],
            "runtime": {
                "duration": 10,
                "start": 283000,
                "end": 283010
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-29",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-64"
            ],
            "outputs": [
                "t-65"
            ],
            "stats": {
                "cycles": 238704.0,
                "instructions": 439328.0,
                "l1_read": 132896.0,
                "l1_write": 67076.0,
                "llc_access": 772.0,
                "microseconds": 81,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 81,
                "start": 283151,
                "end": 283232
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-30",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    64,
                    128
                ],
                "mat2_size": [
                    128,
                    9216
                ]
            },
            "inputs": [
                "t-62",
                "t-65"
            ],
            "outputs": [
                "t-66"
            ],
            "stats": {
                "cycles": 4124608.0,
                "instructions": 8925728.0,
                "l1_read": 3263336.0,
                "l1_write": 137352.0,
                "llc_access": 150955.0,
                "microseconds": 1551,
                "flops": 150994944.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 1551,
                "start": 283275,
                "end": 284826
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-31",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-62"
            ],
            "outputs": [
                "t-67"
            ],
            "stats": {
                "cycles": 261912.0,
                "instructions": 444112.0,
                "l1_read": 133336.0,
                "l1_write": 67723.0,
                "llc_access": 2424.0,
                "microseconds": 129,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 129,
                "start": 284908,
                "end": 285037
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-32",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    128,
                    64
                ],
                "mat2_size": [
                    64,
                    9216
                ]
            },
            "inputs": [
                "t-67",
                "t-17"
            ],
            "outputs": [
                "t-68"
            ],
            "stats": {
                "cycles": 4829584.0,
                "instructions": 9068560.0,
                "l1_read": 3243592.0,
                "l1_write": 144364.0,
                "llc_access": 157683.0,
                "microseconds": 1329,
                "flops": 150994944.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 1329,
                "start": 285106,
                "end": 286435
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-33",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-68"
            ],
            "outputs": [
                "t-69"
            ],
            "stats": {
                "cycles": 270824.0,
                "instructions": 436624.0,
                "l1_read": 132184.0,
                "l1_write": 66622.0,
                "llc_access": 2251.0,
                "microseconds": 85,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 85,
                "start": 286494,
                "end": 286579
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-34",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-62"
            ],
            "outputs": [
                "t-70"
            ],
            "stats": {
                "cycles": 183168.0,
                "instructions": 225168.0,
                "l1_read": 68296.0,
                "l1_write": 34001.0,
                "llc_access": 2575.0,
                "microseconds": 56,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 56,
                "start": 286625,
                "end": 286681
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-35",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-70"
            ],
            "outputs": [
                "t-71"
            ],
            "stats": {
                "cycles": 17256.0,
                "instructions": 6528.0,
                "l1_read": 2040.0,
                "l1_write": 1175.0,
                "llc_access": 315.0,
                "microseconds": 3,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                [
                    128
                ]
            ],
            "runtime": {
                "duration": 3,
                "start": 286721,
                "end": 286724
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-36",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-73",
                "t-71"
            ],
            "outputs": [
                "t-74"
            ],
            "stats": {
                "cycles": 25272.0,
                "instructions": 8128.0,
                "l1_read": 2576.0,
                "l1_write": 1405.0,
                "llc_access": 639.0,
                "microseconds": 5,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                1
            ],
            "runtime": {
                "duration": 5,
                "start": 286856,
                "end": 286861
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-37",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-69"
            ],
            "outputs": [
                "t-75"
            ],
            "stats": {
                "cycles": 250936.0,
                "instructions": 431440.0,
                "l1_read": 130976.0,
                "l1_write": 65828.0,
                "llc_access": 750.0,
                "microseconds": 96,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 96,
                "start": 286977,
                "end": 287073
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-38",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-77",
                "t-75"
            ],
            "outputs": [
                "t-78"
            ],
            "stats": {
                "cycles": 2333736.0,
                "instructions": 745360.0,
                "l1_read": 371192.0,
                "l1_write": 148851.0,
                "llc_access": 148797.0,
                "microseconds": 673,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                1
            ],
            "runtime": {
                "duration": 673,
                "start": 287198,
                "end": 287871
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: ReshapeAliasBackward0/ReshapeAliasBackward0/op-39",
            "optype": "aten::reshape",
            "params": {},
            "inputs": [
                "t-66"
            ],
            "outputs": [
                "t-79"
            ],
            "stats": {
                "cycles": 143032.0,
                "instructions": 221584.0,
                "l1_read": 67232.0,
                "l1_write": 33979.0,
                "llc_access": 1123.0,
                "microseconds": 53,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                [
                    64,
                    64,
                    12,
                    12
                ]
            ],
            "runtime": {
                "duration": 53,
                "start": 288060,
                "end": 288113
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: MulBackward0/MulBackward0/op-40",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    64,
                    64,
                    12,
                    12
                ]
            },
            "inputs": [
                "t-79",
                "t-81"
            ],
            "outputs": [
                "t-82"
            ],
            "stats": {
                "cycles": 910928.0,
                "instructions": 341040.0,
                "l1_read": 150296.0,
                "l1_write": 75387.0,
                "llc_access": 112558.0,
                "microseconds": 301,
                "flops": 589824.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 301,
                "start": 288253,
                "end": 288554
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: MaxPool2DWithIndicesBackward0/MaxPool2DWithIndicesBackward0/op-41",
            "optype": "aten::max_pool2d_with_indices_backward",
            "params": {},
            "inputs": [
                "t-82",
                "t-14",
                "t-84"
            ],
            "outputs": [
                "t-85"
            ],
            "stats": {
                "cycles": 7243080.0,
                "instructions": 8204016.0,
                "l1_read": 2089000.0,
                "l1_write": 962872.0,
                "llc_access": 410944.0,
                "microseconds": 1974,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                [
                    2,
                    2
                ],
                [],
                [
                    0,
                    0
                ],
                [
                    1,
                    1
                ],
                false
            ],
            "runtime": {
                "duration": 1974,
                "start": 288731,
                "end": 290705
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: ReluBackward0/ReluBackward0/op-42",
            "optype": "aten::threshold_backward",
            "params": {},
            "inputs": [
                "t-85",
                "t-82"
            ],
            "outputs": [
                "t-86"
            ],
            "stats": {
                "cycles": 5946640.0,
                "instructions": 2516096.0,
                "l1_read": 1182512.0,
                "l1_write": 296588.0,
                "llc_access": 444660.0,
                "microseconds": 1670,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                0
            ],
            "runtime": {
                "duration": 1670,
                "start": 290851,
                "end": 292521
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: MkldnnConvolutionBackward0/MkldnnConvolutionBackward0/op-43",
            "optype": "aten::mkldnn_convolution_backward",
            "params": {},
            "inputs": [
                "t-8",
                "t-86",
                "t-10"
            ],
            "outputs": [
                "t-87",
                "t-88",
                "t-89"
            ],
            "stats": {
                "cycles": 71511616.0,
                "instructions": 104197504.0,
                "l1_read": 93555784.0,
                "l1_write": 3770820.0,
                "llc_access": 1465959.0,
                "microseconds": 21984,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                [
                    0,
                    0
                ],
                [
                    1,
                    1
                ],
                [
                    1,
                    1
                ],
                1,
                [
                    true,
                    true,
                    true
                ]
            ],
            "runtime": {
                "duration": 21984,
                "start": 292700,
                "end": 314684
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-44",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-91",
                "t-88"
            ],
            "outputs": [
                "t-92"
            ],
            "stats": {
                "cycles": 79472.0,
                "instructions": 19776.0,
                "l1_read": 8320.0,
                "l1_write": 3708.0,
                "llc_access": 2633.0,
                "microseconds": 21,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                1
            ],
            "runtime": {
                "duration": 21,
                "start": 314845,
                "end": 314866
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-45",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-94",
                "t-89"
            ],
            "outputs": [
                "t-95"
            ],
            "stats": {
                "cycles": 15616.0,
                "instructions": 7936.0,
                "l1_read": 2496.0,
                "l1_write": 1372.0,
                "llc_access": 392.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                1
            ],
            "runtime": {
                "duration": 4,
                "start": 315002,
                "end": 315006
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: ReluBackward0/ReluBackward0/op-46",
            "optype": "aten::threshold_backward",
            "params": {},
            "inputs": [
                "t-87",
                "t-97"
            ],
            "outputs": [
                "t-98"
            ],
            "stats": {
                "cycles": 3490608.0,
                "instructions": 1480896.0,
                "l1_read": 695232.0,
                "l1_write": 174812.0,
                "llc_access": 261867.0,
                "microseconds": 1039,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                0
            ],
            "runtime": {
                "duration": 1039,
                "start": 315168,
                "end": 316207
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: MkldnnConvolutionBackward0/MkldnnConvolutionBackward0/op-47",
            "optype": "aten::mkldnn_convolution_backward",
            "params": {},
            "inputs": [
                "t-2",
                "t-98",
                "t-4"
            ],
            "outputs": [
                "t-99",
                "t-100"
            ],
            "stats": {
                "cycles": 5712448.0,
                "instructions": 4094304.0,
                "l1_read": 1845024.0,
                "l1_write": 409104.0,
                "llc_access": 284767.0,
                "microseconds": 1738,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                [
                    0,
                    0
                ],
                [
                    1,
                    1
                ],
                [
                    1,
                    1
                ],
                1,
                [
                    false,
                    true,
                    true
                ]
            ],
            "runtime": {
                "duration": 1738,
                "start": 316384,
                "end": 318122
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-48",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-102",
                "t-99"
            ],
            "outputs": [
                "t-103"
            ],
            "stats": {
                "cycles": 43376.0,
                "instructions": 8064.0,
                "l1_read": 2576.0,
                "l1_write": 1404.0,
                "llc_access": 1138.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 318267,
                "end": 318279
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-49",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-105",
                "t-100"
            ],
            "outputs": [
                "t-106"
            ],
            "stats": {
                "cycles": 12384.0,
                "instructions": 7904.0,
                "l1_read": 2480.0,
                "l1_write": 1370.0,
                "llc_access": 96.0,
                "microseconds": 3,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                1
            ],
            "runtime": {
                "duration": 3,
                "start": 318407,
                "end": 318410
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 54, in train\n    loss.backward()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 154, in backward\n    Variable._execution_engine.run_backward(\n"
            ]
        },
        {
            "name": "op-50",
            "optype": "aten::zeros",
            "params": {},
            "inputs": [],
            "outputs": [
                "t-107"
            ],
            "stats": {
                "cycles": 390656.0,
                "instructions": 501664.0,
                "l1_read": 151648.0,
                "l1_write": 75684.0,
                "llc_access": 4308.0,
                "microseconds": 136,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                [
                    1
                ],
                6,
                false
            ],
            "runtime": {
                "duration": 136,
                "start": 319020,
                "end": 319156
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 87, in wrapper\n    with torch.autograd.profiler.record_function(profile_name):\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/profiler.py\", line 432, in __init__\n    self.handle: torch.Tensor = torch.zeros(1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-51",
            "optype": "aten::empty",
            "params": {},
            "inputs": [],
            "outputs": [
                "t-108"
            ],
            "stats": {
                "cycles": 8016.0,
                "instructions": 5376.0,
                "l1_read": 1680.0,
                "l1_write": 924.0,
                "llc_access": 108.0,
                "microseconds": 1,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                [
                    16
                ],
                0
            ],
            "runtime": {
                "duration": 1,
                "start": 319274,
                "end": 319275
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 87, in wrapper\n    with torch.autograd.profiler.record_function(profile_name):\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/profiler.py\", line 435, in __enter__\n    self.handle = torch.ops.profiler._record_function_enter(self.name)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-52",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-110",
                "t-107"
            ],
            "outputs": [
                "t-111"
            ],
            "stats": {
                "cycles": 887072.0,
                "instructions": 1307744.0,
                "l1_read": 396304.0,
                "l1_write": 198792.0,
                "llc_access": 8038.0,
                "microseconds": 280,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 280,
                "start": 319938,
                "end": 320218
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 201, in adadelta\n    square_avg.mul_(rho).addcmul_(grad, grad, value=1 - rho)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-53",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-111",
                "t-103",
                "t-103"
            ],
            "outputs": [
                "t-112"
            ],
            "stats": {
                "cycles": 30384.0,
                "instructions": 8544.0,
                "l1_read": 2720.0,
                "l1_write": 1478.0,
                "llc_access": 466.0,
                "microseconds": 8,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 8,
                "start": 320303,
                "end": 320311
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 201, in adadelta\n    square_avg.mul_(rho).addcmul_(grad, grad, value=1 - rho)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-54",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    32,
                    1,
                    3,
                    3
                ]
            },
            "inputs": [
                "t-112",
                "t-114"
            ],
            "outputs": [
                "t-115"
            ],
            "stats": {
                "cycles": 702880.0,
                "instructions": 1314304.0,
                "l1_read": 397632.0,
                "l1_write": 199756.0,
                "llc_access": 2724.0,
                "microseconds": 248,
                "flops": 288.0
            },
            "meta": {},
            "args": [
                1
            ],
            "runtime": {
                "duration": 248,
                "start": 320388,
                "end": 320636
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 202, in adadelta\n    std = square_avg.add(eps).sqrt_()\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-55",
            "optype": "aten::sqrt_",
            "params": {},
            "inputs": [
                "t-115"
            ],
            "outputs": [
                "t-116"
            ],
            "stats": {
                "cycles": 47696.0,
                "instructions": 7680.0,
                "l1_read": 2320.0,
                "l1_write": 1280.0,
                "llc_access": 591.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 320696,
                "end": 320710
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 202, in adadelta\n    std = square_avg.add(eps).sqrt_()\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-56",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    32,
                    1,
                    3,
                    3
                ]
            },
            "inputs": [
                "t-118",
                "t-120"
            ],
            "outputs": [
                "t-121"
            ],
            "stats": {
                "cycles": 691504.0,
                "instructions": 1320000.0,
                "l1_read": 398928.0,
                "l1_write": 200116.0,
                "llc_access": 1979.0,
                "microseconds": 242,
                "flops": 288.0
            },
            "meta": {},
            "args": [
                1
            ],
            "runtime": {
                "duration": 242,
                "start": 320793,
                "end": 321035
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-57",
            "optype": "aten::sqrt_",
            "params": {},
            "inputs": [
                "t-121"
            ],
            "outputs": [
                "t-122"
            ],
            "stats": {
                "cycles": 16480.0,
                "instructions": 7648.0,
                "l1_read": 2336.0,
                "l1_write": 1280.0,
                "llc_access": 201.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 4,
                "start": 321103,
                "end": 321107
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-58",
            "optype": "aten::div_",
            "params": {},
            "inputs": [
                "t-122",
                "t-116"
            ],
            "outputs": [
                "t-123"
            ],
            "stats": {
                "cycles": 22528.0,
                "instructions": 7744.0,
                "l1_read": 2432.0,
                "l1_write": 1346.0,
                "llc_access": 306.0,
                "microseconds": 5,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 5,
                "start": 321169,
                "end": 321174
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-59",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-123",
                "t-103"
            ],
            "outputs": [
                "t-124"
            ],
            "stats": {
                "cycles": 13360.0,
                "instructions": 7744.0,
                "l1_read": 2432.0,
                "l1_write": 1346.0,
                "llc_access": 263.0,
                "microseconds": 3,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 3,
                "start": 321232,
                "end": 321235
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-60",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-4",
                "t-124"
            ],
            "outputs": [
                "t-125"
            ],
            "stats": {
                "cycles": 16208.0,
                "instructions": 7968.0,
                "l1_read": 2544.0,
                "l1_write": 1388.0,
                "llc_access": 306.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                -1.0
            ],
            "runtime": {
                "duration": 4,
                "start": 321300,
                "end": 321304
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 204, in adadelta\n    param.add_(delta, alpha=-lr)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-61",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-118",
                "t-127"
            ],
            "outputs": [
                "t-128"
            ],
            "stats": {
                "cycles": 673360.0,
                "instructions": 1308672.0,
                "l1_read": 396704.0,
                "l1_write": 199152.0,
                "llc_access": 1659.0,
                "microseconds": 239,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 239,
                "start": 321364,
                "end": 321603
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 205, in adadelta\n    acc_delta.mul_(rho).addcmul_(delta, delta, value=1 - rho)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-62",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-128",
                "t-124",
                "t-124"
            ],
            "outputs": [
                "t-129"
            ],
            "stats": {
                "cycles": 15920.0,
                "instructions": 8512.0,
                "l1_read": 2720.0,
                "l1_write": 1478.0,
                "llc_access": 299.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 4,
                "start": 321660,
                "end": 321664
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 205, in adadelta\n    acc_delta.mul_(rho).addcmul_(delta, delta, value=1 - rho)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-63",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-131",
                "t-133"
            ],
            "outputs": [
                "t-134"
            ],
            "stats": {
                "cycles": 679616.0,
                "instructions": 1312032.0,
                "l1_read": 397344.0,
                "l1_write": 199324.0,
                "llc_access": 1585.0,
                "microseconds": 229,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 229,
                "start": 321724,
                "end": 321953
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 201, in adadelta\n    square_avg.mul_(rho).addcmul_(grad, grad, value=1 - rho)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-64",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-134",
                "t-106",
                "t-106"
            ],
            "outputs": [
                "t-135"
            ],
            "stats": {
                "cycles": 13328.0,
                "instructions": 8352.0,
                "l1_read": 2608.0,
                "l1_write": 1444.0,
                "llc_access": 96.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 2,
                "start": 322007,
                "end": 322009
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 201, in adadelta\n    square_avg.mul_(rho).addcmul_(grad, grad, value=1 - rho)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-65",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    32
                ]
            },
            "inputs": [
                "t-135",
                "t-137"
            ],
            "outputs": [
                "t-138"
            ],
            "stats": {
                "cycles": 670480.0,
                "instructions": 1310656.0,
                "l1_read": 397120.0,
                "l1_write": 199404.0,
                "llc_access": 1367.0,
                "microseconds": 212,
                "flops": 32.0
            },
            "meta": {},
            "args": [
                1
            ],
            "runtime": {
                "duration": 212,
                "start": 322069,
                "end": 322281
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 202, in adadelta\n    std = square_avg.add(eps).sqrt_()\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-66",
            "optype": "aten::sqrt_",
            "params": {},
            "inputs": [
                "t-138"
            ],
            "outputs": [
                "t-139"
            ],
            "stats": {
                "cycles": 17456.0,
                "instructions": 7296.0,
                "l1_read": 2288.0,
                "l1_write": 1252.0,
                "llc_access": 369.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 4,
                "start": 322333,
                "end": 322337
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 202, in adadelta\n    std = square_avg.add(eps).sqrt_()\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-67",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    32
                ]
            },
            "inputs": [
                "t-141",
                "t-115"
            ],
            "outputs": [
                "t-142"
            ],
            "stats": {
                "cycles": 678320.0,
                "instructions": 1317984.0,
                "l1_read": 398592.0,
                "l1_write": 200214.0,
                "llc_access": 1586.0,
                "microseconds": 230,
                "flops": 32.0
            },
            "meta": {},
            "args": [
                1
            ],
            "runtime": {
                "duration": 230,
                "start": 322408,
                "end": 322638
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-68",
            "optype": "aten::sqrt_",
            "params": {},
            "inputs": [
                "t-142"
            ],
            "outputs": [
                "t-143"
            ],
            "stats": {
                "cycles": 13984.0,
                "instructions": 7296.0,
                "l1_read": 2288.0,
                "l1_write": 1252.0,
                "llc_access": 183.0,
                "microseconds": 3,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 3,
                "start": 322693,
                "end": 322696
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-69",
            "optype": "aten::div_",
            "params": {},
            "inputs": [
                "t-143",
                "t-139"
            ],
            "outputs": [
                "t-144"
            ],
            "stats": {
                "cycles": 14480.0,
                "instructions": 7616.0,
                "l1_read": 2368.0,
                "l1_write": 1312.0,
                "llc_access": 219.0,
                "microseconds": 3,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 3,
                "start": 322751,
                "end": 322754
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-70",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-144",
                "t-106"
            ],
            "outputs": [
                "t-145"
            ],
            "stats": {
                "cycles": 13312.0,
                "instructions": 7616.0,
                "l1_read": 2368.0,
                "l1_write": 1312.0,
                "llc_access": 204.0,
                "microseconds": 3,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 3,
                "start": 322811,
                "end": 322814
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-71",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-6",
                "t-145"
            ],
            "outputs": [
                "t-146"
            ],
            "stats": {
                "cycles": 14624.0,
                "instructions": 7808.0,
                "l1_read": 2448.0,
                "l1_write": 1352.0,
                "llc_access": 214.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                -1.0
            ],
            "runtime": {
                "duration": 4,
                "start": 322875,
                "end": 322879
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 204, in adadelta\n    param.add_(delta, alpha=-lr)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-72",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-141",
                "t-148"
            ],
            "outputs": [
                "t-149"
            ],
            "stats": {
                "cycles": 660640.0,
                "instructions": 1299328.0,
                "l1_read": 394592.0,
                "l1_write": 197704.0,
                "llc_access": 1542.0,
                "microseconds": 229,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 229,
                "start": 322953,
                "end": 323182
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 205, in adadelta\n    acc_delta.mul_(rho).addcmul_(delta, delta, value=1 - rho)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-73",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-149",
                "t-145",
                "t-145"
            ],
            "outputs": [
                "t-150"
            ],
            "stats": {
                "cycles": 14784.0,
                "instructions": 8352.0,
                "l1_read": 2608.0,
                "l1_write": 1444.0,
                "llc_access": 245.0,
                "microseconds": 3,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 3,
                "start": 323242,
                "end": 323245
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 205, in adadelta\n    acc_delta.mul_(rho).addcmul_(delta, delta, value=1 - rho)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-74",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-152",
                "t-154"
            ],
            "outputs": [
                "t-155"
            ],
            "stats": {
                "cycles": 682272.0,
                "instructions": 1309600.0,
                "l1_read": 397248.0,
                "l1_write": 200082.0,
                "llc_access": 2551.0,
                "microseconds": 234,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 234,
                "start": 323305,
                "end": 323539
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 201, in adadelta\n    square_avg.mul_(rho).addcmul_(grad, grad, value=1 - rho)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-75",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-155",
                "t-92",
                "t-92"
            ],
            "outputs": [
                "t-156"
            ],
            "stats": {
                "cycles": 32224.0,
                "instructions": 22144.0,
                "l1_read": 10672.0,
                "l1_write": 3748.0,
                "llc_access": 1308.0,
                "microseconds": 8,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 8,
                "start": 323607,
                "end": 323615
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 201, in adadelta\n    square_avg.mul_(rho).addcmul_(grad, grad, value=1 - rho)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-76",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    64,
                    32,
                    3,
                    3
                ]
            },
            "inputs": [
                "t-156",
                "t-158"
            ],
            "outputs": [
                "t-159"
            ],
            "stats": {
                "cycles": 713536.0,
                "instructions": 1318528.0,
                "l1_read": 399696.0,
                "l1_write": 200764.0,
                "llc_access": 4111.0,
                "microseconds": 262,
                "flops": 18432.0
            },
            "meta": {},
            "args": [
                1
            ],
            "runtime": {
                "duration": 262,
                "start": 323683,
                "end": 323945
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 202, in adadelta\n    std = square_avg.add(eps).sqrt_()\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-77",
            "optype": "aten::sqrt_",
            "params": {},
            "inputs": [
                "t-159"
            ],
            "outputs": [
                "t-160"
            ],
            "stats": {
                "cycles": 51632.0,
                "instructions": 29216.0,
                "l1_read": 3456.0,
                "l1_write": 2414.0,
                "llc_access": 577.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 324007,
                "end": 324022
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 202, in adadelta\n    std = square_avg.add(eps).sqrt_()\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-78",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    64,
                    32,
                    3,
                    3
                ]
            },
            "inputs": [
                "t-162",
                "t-138"
            ],
            "outputs": [
                "t-163"
            ],
            "stats": {
                "cycles": 706544.0,
                "instructions": 1319264.0,
                "l1_read": 399808.0,
                "l1_write": 200912.0,
                "llc_access": 4477.0,
                "microseconds": 251,
                "flops": 18432.0
            },
            "meta": {},
            "args": [
                1
            ],
            "runtime": {
                "duration": 251,
                "start": 324103,
                "end": 324354
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-79",
            "optype": "aten::sqrt_",
            "params": {},
            "inputs": [
                "t-163"
            ],
            "outputs": [
                "t-164"
            ],
            "stats": {
                "cycles": 28080.0,
                "instructions": 29216.0,
                "l1_read": 3456.0,
                "l1_write": 2414.0,
                "llc_access": 350.0,
                "microseconds": 7,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 7,
                "start": 324413,
                "end": 324420
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-80",
            "optype": "aten::div_",
            "params": {},
            "inputs": [
                "t-164",
                "t-160"
            ],
            "outputs": [
                "t-165"
            ],
            "stats": {
                "cycles": 29520.0,
                "instructions": 17920.0,
                "l1_read": 6976.0,
                "l1_write": 3612.0,
                "llc_access": 859.0,
                "microseconds": 8,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 8,
                "start": 324478,
                "end": 324486
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-81",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-165",
                "t-92"
            ],
            "outputs": [
                "t-166"
            ],
            "stats": {
                "cycles": 31520.0,
                "instructions": 17952.0,
                "l1_read": 6976.0,
                "l1_write": 3612.0,
                "llc_access": 1412.0,
                "microseconds": 8,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 8,
                "start": 324547,
                "end": 324555
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-82",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-10",
                "t-166"
            ],
            "outputs": [
                "t-167"
            ],
            "stats": {
                "cycles": 36544.0,
                "instructions": 19328.0,
                "l1_read": 8208.0,
                "l1_write": 3652.0,
                "llc_access": 1497.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                -1.0
            ],
            "runtime": {
                "duration": 10,
                "start": 324621,
                "end": 324631
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 204, in adadelta\n    param.add_(delta, alpha=-lr)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-83",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-162",
                "t-169"
            ],
            "outputs": [
                "t-170"
            ],
            "stats": {
                "cycles": 679664.0,
                "instructions": 1308128.0,
                "l1_read": 396944.0,
                "l1_write": 199956.0,
                "llc_access": 3321.0,
                "microseconds": 241,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 241,
                "start": 324692,
                "end": 324933
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 205, in adadelta\n    acc_delta.mul_(rho).addcmul_(delta, delta, value=1 - rho)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-84",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-170",
                "t-166",
                "t-166"
            ],
            "outputs": [
                "t-171"
            ],
            "stats": {
                "cycles": 29952.0,
                "instructions": 22144.0,
                "l1_read": 10672.0,
                "l1_write": 3746.0,
                "llc_access": 465.0,
                "microseconds": 8,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 8,
                "start": 324993,
                "end": 325001
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 205, in adadelta\n    acc_delta.mul_(rho).addcmul_(delta, delta, value=1 - rho)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-85",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-173",
                "t-175"
            ],
            "outputs": [
                "t-176"
            ],
            "stats": {
                "cycles": 651920.0,
                "instructions": 1298048.0,
                "l1_read": 394208.0,
                "l1_write": 197452.0,
                "llc_access": 1741.0,
                "microseconds": 230,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 230,
                "start": 325072,
                "end": 325302
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 201, in adadelta\n    square_avg.mul_(rho).addcmul_(grad, grad, value=1 - rho)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-86",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-176",
                "t-95",
                "t-95"
            ],
            "outputs": [
                "t-177"
            ],
            "stats": {
                "cycles": 13904.0,
                "instructions": 8352.0,
                "l1_read": 2640.0,
                "l1_write": 1448.0,
                "llc_access": 114.0,
                "microseconds": 3,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 3,
                "start": 325354,
                "end": 325357
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 201, in adadelta\n    square_avg.mul_(rho).addcmul_(grad, grad, value=1 - rho)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-87",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    64
                ]
            },
            "inputs": [
                "t-177",
                "t-179"
            ],
            "outputs": [
                "t-180"
            ],
            "stats": {
                "cycles": 686336.0,
                "instructions": 1302528.0,
                "l1_read": 395200.0,
                "l1_write": 198060.0,
                "llc_access": 2752.0,
                "microseconds": 246,
                "flops": 64.0
            },
            "meta": {},
            "args": [
                1
            ],
            "runtime": {
                "duration": 246,
                "start": 325417,
                "end": 325663
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 202, in adadelta\n    std = square_avg.add(eps).sqrt_()\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-88",
            "optype": "aten::sqrt_",
            "params": {},
            "inputs": [
                "t-180"
            ],
            "outputs": [
                "t-181"
            ],
            "stats": {
                "cycles": 18976.0,
                "instructions": 7328.0,
                "l1_read": 2304.0,
                "l1_write": 1254.0,
                "llc_access": 446.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 4,
                "start": 325714,
                "end": 325718
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 202, in adadelta\n    std = square_avg.add(eps).sqrt_()\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-89",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    64
                ]
            },
            "inputs": [
                "t-183",
                "t-159"
            ],
            "outputs": [
                "t-184"
            ],
            "stats": {
                "cycles": 679056.0,
                "instructions": 1310592.0,
                "l1_read": 396592.0,
                "l1_write": 198700.0,
                "llc_access": 1850.0,
                "microseconds": 230,
                "flops": 64.0
            },
            "meta": {},
            "args": [
                1
            ],
            "runtime": {
                "duration": 230,
                "start": 325793,
                "end": 326023
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-90",
            "optype": "aten::sqrt_",
            "params": {},
            "inputs": [
                "t-184"
            ],
            "outputs": [
                "t-185"
            ],
            "stats": {
                "cycles": 13824.0,
                "instructions": 7360.0,
                "l1_read": 2304.0,
                "l1_write": 1256.0,
                "llc_access": 197.0,
                "microseconds": 3,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 3,
                "start": 326078,
                "end": 326081
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-91",
            "optype": "aten::div_",
            "params": {},
            "inputs": [
                "t-185",
                "t-181"
            ],
            "outputs": [
                "t-186"
            ],
            "stats": {
                "cycles": 13616.0,
                "instructions": 7616.0,
                "l1_read": 2384.0,
                "l1_write": 1314.0,
                "llc_access": 234.0,
                "microseconds": 3,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 3,
                "start": 326136,
                "end": 326139
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-92",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-186",
                "t-95"
            ],
            "outputs": [
                "t-187"
            ],
            "stats": {
                "cycles": 13216.0,
                "instructions": 7616.0,
                "l1_read": 2384.0,
                "l1_write": 1314.0,
                "llc_access": 257.0,
                "microseconds": 3,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 3,
                "start": 326197,
                "end": 326200
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-93",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-12",
                "t-187"
            ],
            "outputs": [
                "t-188"
            ],
            "stats": {
                "cycles": 14800.0,
                "instructions": 7840.0,
                "l1_read": 2464.0,
                "l1_write": 1356.0,
                "llc_access": 250.0,
                "microseconds": 3,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                -1.0
            ],
            "runtime": {
                "duration": 3,
                "start": 326258,
                "end": 326261
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 204, in adadelta\n    param.add_(delta, alpha=-lr)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-94",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-183",
                "t-190"
            ],
            "outputs": [
                "t-191"
            ],
            "stats": {
                "cycles": 649344.0,
                "instructions": 1300608.0,
                "l1_read": 394704.0,
                "l1_write": 197628.0,
                "llc_access": 1310.0,
                "microseconds": 220,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 220,
                "start": 326317,
                "end": 326537
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 205, in adadelta\n    acc_delta.mul_(rho).addcmul_(delta, delta, value=1 - rho)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-95",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-191",
                "t-187",
                "t-187"
            ],
            "outputs": [
                "t-192"
            ],
            "stats": {
                "cycles": 15328.0,
                "instructions": 8384.0,
                "l1_read": 2624.0,
                "l1_write": 1448.0,
                "llc_access": 282.0,
                "microseconds": 3,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 3,
                "start": 326595,
                "end": 326598
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 205, in adadelta\n    acc_delta.mul_(rho).addcmul_(delta, delta, value=1 - rho)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-96",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-194",
                "t-196"
            ],
            "outputs": [
                "t-197"
            ],
            "stats": {
                "cycles": 1886752.0,
                "instructions": 1815360.0,
                "l1_read": 541904.0,
                "l1_write": 345008.0,
                "llc_access": 75770.0,
                "microseconds": 582,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 582,
                "start": 326654,
                "end": 327236
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 201, in adadelta\n    square_avg.mul_(rho).addcmul_(grad, grad, value=1 - rho)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-97",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-197",
                "t-78",
                "t-78"
            ],
            "outputs": [
                "t-198"
            ],
            "stats": {
                "cycles": 2411328.0,
                "instructions": 893120.0,
                "l1_read": 518704.0,
                "l1_write": 148902.0,
                "llc_access": 149342.0,
                "microseconds": 715,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 715,
                "start": 327326,
                "end": 328041
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 201, in adadelta\n    square_avg.mul_(rho).addcmul_(grad, grad, value=1 - rho)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-98",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    128,
                    9216
                ]
            },
            "inputs": [
                "t-198",
                "t-200"
            ],
            "outputs": [
                "t-201"
            ],
            "stats": {
                "cycles": 2185872.0,
                "instructions": 1966720.0,
                "l1_read": 616432.0,
                "l1_write": 345562.0,
                "llc_access": 152794.0,
                "microseconds": 696,
                "flops": 1179648.0
            },
            "meta": {},
            "args": [
                1
            ],
            "runtime": {
                "duration": 696,
                "start": 328144,
                "end": 328840
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 202, in adadelta\n    std = square_avg.add(eps).sqrt_()\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-99",
            "optype": "aten::sqrt_",
            "params": {},
            "inputs": [
                "t-201"
            ],
            "outputs": [
                "t-202"
            ],
            "stats": {
                "cycles": 892640.0,
                "instructions": 1408160.0,
                "l1_read": 76032.0,
                "l1_write": 74990.0,
                "llc_access": 75489.0,
                "microseconds": 289,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 289,
                "start": 328930,
                "end": 329219
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 202, in adadelta\n    std = square_avg.add(eps).sqrt_()\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-100",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    128,
                    9216
                ]
            },
            "inputs": [
                "t-204",
                "t-180"
            ],
            "outputs": [
                "t-205"
            ],
            "stats": {
                "cycles": 2869888.0,
                "instructions": 1970208.0,
                "l1_read": 617280.0,
                "l1_write": 346384.0,
                "llc_access": 153761.0,
                "microseconds": 902,
                "flops": 1179648.0
            },
            "meta": {},
            "args": [
                1
            ],
            "runtime": {
                "duration": 902,
                "start": 329314,
                "end": 330216
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-101",
            "optype": "aten::sqrt_",
            "params": {},
            "inputs": [
                "t-205"
            ],
            "outputs": [
                "t-206"
            ],
            "stats": {
                "cycles": 1156400.0,
                "instructions": 1408128.0,
                "l1_read": 76048.0,
                "l1_write": 74990.0,
                "llc_access": 75651.0,
                "microseconds": 337,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 337,
                "start": 330329,
                "end": 330666
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-102",
            "optype": "aten::div_",
            "params": {},
            "inputs": [
                "t-206",
                "t-202"
            ],
            "outputs": [
                "t-207"
            ],
            "stats": {
                "cycles": 1349376.0,
                "instructions": 671136.0,
                "l1_read": 297296.0,
                "l1_write": 148770.0,
                "llc_access": 149390.0,
                "microseconds": 384,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 384,
                "start": 330773,
                "end": 331157
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-103",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-207",
                "t-78"
            ],
            "outputs": [
                "t-208"
            ],
            "stats": {
                "cycles": 1740928.0,
                "instructions": 671168.0,
                "l1_read": 297280.0,
                "l1_write": 148770.0,
                "llc_access": 149562.0,
                "microseconds": 511,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 511,
                "start": 331264,
                "end": 331775
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-104",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-19",
                "t-208"
            ],
            "outputs": [
                "t-209"
            ],
            "stats": {
                "cycles": 1695344.0,
                "instructions": 745120.0,
                "l1_read": 371104.0,
                "l1_write": 148810.0,
                "llc_access": 149554.0,
                "microseconds": 526,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                -1.0
            ],
            "runtime": {
                "duration": 526,
                "start": 331897,
                "end": 332423
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 204, in adadelta\n    param.add_(delta, alpha=-lr)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-105",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-204",
                "t-211"
            ],
            "outputs": [
                "t-212"
            ],
            "stats": {
                "cycles": 1858320.0,
                "instructions": 1817504.0,
                "l1_read": 542368.0,
                "l1_write": 345188.0,
                "llc_access": 79941.0,
                "microseconds": 611,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 611,
                "start": 332537,
                "end": 333148
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 205, in adadelta\n    acc_delta.mul_(rho).addcmul_(delta, delta, value=1 - rho)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-106",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-212",
                "t-208",
                "t-208"
            ],
            "outputs": [
                "t-213"
            ],
            "stats": {
                "cycles": 1696400.0,
                "instructions": 893120.0,
                "l1_read": 518704.0,
                "l1_write": 148904.0,
                "llc_access": 149285.0,
                "microseconds": 483,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 483,
                "start": 333232,
                "end": 333715
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 205, in adadelta\n    acc_delta.mul_(rho).addcmul_(delta, delta, value=1 - rho)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-107",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-215",
                "t-217"
            ],
            "outputs": [
                "t-218"
            ],
            "stats": {
                "cycles": 690320.0,
                "instructions": 1298880.0,
                "l1_read": 394368.0,
                "l1_write": 197560.0,
                "llc_access": 4294.0,
                "microseconds": 231,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 231,
                "start": 333803,
                "end": 334034
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 201, in adadelta\n    square_avg.mul_(rho).addcmul_(grad, grad, value=1 - rho)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-108",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-218",
                "t-74",
                "t-74"
            ],
            "outputs": [
                "t-219"
            ],
            "stats": {
                "cycles": 15504.0,
                "instructions": 8416.0,
                "l1_read": 2656.0,
                "l1_write": 1456.0,
                "llc_access": 335.0,
                "microseconds": 3,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 3,
                "start": 334091,
                "end": 334094
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 201, in adadelta\n    square_avg.mul_(rho).addcmul_(grad, grad, value=1 - rho)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-109",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    128
                ]
            },
            "inputs": [
                "t-219",
                "t-221"
            ],
            "outputs": [
                "t-222"
            ],
            "stats": {
                "cycles": 665600.0,
                "instructions": 1300032.0,
                "l1_read": 394688.0,
                "l1_write": 197808.0,
                "llc_access": 1889.0,
                "microseconds": 213,
                "flops": 128.0
            },
            "meta": {},
            "args": [
                1
            ],
            "runtime": {
                "duration": 213,
                "start": 334171,
                "end": 334384
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 202, in adadelta\n    std = square_avg.add(eps).sqrt_()\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-110",
            "optype": "aten::sqrt_",
            "params": {},
            "inputs": [
                "t-222"
            ],
            "outputs": [
                "t-223"
            ],
            "stats": {
                "cycles": 24960.0,
                "instructions": 7456.0,
                "l1_read": 2320.0,
                "l1_write": 1266.0,
                "llc_access": 546.0,
                "microseconds": 5,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 5,
                "start": 334449,
                "end": 334454
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 202, in adadelta\n    std = square_avg.add(eps).sqrt_()\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-111",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    128
                ]
            },
            "inputs": [
                "t-225",
                "t-201"
            ],
            "outputs": [
                "t-226"
            ],
            "stats": {
                "cycles": 672912.0,
                "instructions": 1304320.0,
                "l1_read": 395488.0,
                "l1_write": 198210.0,
                "llc_access": 1984.0,
                "microseconds": 234,
                "flops": 128.0
            },
            "meta": {},
            "args": [
                1
            ],
            "runtime": {
                "duration": 234,
                "start": 334523,
                "end": 334757
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-112",
            "optype": "aten::sqrt_",
            "params": {},
            "inputs": [
                "t-226"
            ],
            "outputs": [
                "t-227"
            ],
            "stats": {
                "cycles": 14032.0,
                "instructions": 7488.0,
                "l1_read": 2320.0,
                "l1_write": 1266.0,
                "llc_access": 193.0,
                "microseconds": 3,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 3,
                "start": 334816,
                "end": 334819
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-113",
            "optype": "aten::div_",
            "params": {},
            "inputs": [
                "t-227",
                "t-223"
            ],
            "outputs": [
                "t-228"
            ],
            "stats": {
                "cycles": 15952.0,
                "instructions": 7648.0,
                "l1_read": 2384.0,
                "l1_write": 1322.0,
                "llc_access": 284.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 4,
                "start": 334875,
                "end": 334879
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-114",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-228",
                "t-74"
            ],
            "outputs": [
                "t-229"
            ],
            "stats": {
                "cycles": 12144.0,
                "instructions": 7648.0,
                "l1_read": 2384.0,
                "l1_write": 1322.0,
                "llc_access": 246.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 2,
                "start": 334934,
                "end": 334936
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-115",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-21",
                "t-229"
            ],
            "outputs": [
                "t-230"
            ],
            "stats": {
                "cycles": 16160.0,
                "instructions": 7904.0,
                "l1_read": 2496.0,
                "l1_write": 1364.0,
                "llc_access": 251.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                -1.0
            ],
            "runtime": {
                "duration": 4,
                "start": 334995,
                "end": 334999
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 204, in adadelta\n    param.add_(delta, alpha=-lr)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-116",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-225",
                "t-232"
            ],
            "outputs": [
                "t-233"
            ],
            "stats": {
                "cycles": 670144.0,
                "instructions": 1305344.0,
                "l1_read": 395280.0,
                "l1_write": 198120.0,
                "llc_access": 1699.0,
                "microseconds": 228,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 228,
                "start": 335057,
                "end": 335285
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 205, in adadelta\n    acc_delta.mul_(rho).addcmul_(delta, delta, value=1 - rho)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-117",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-233",
                "t-229",
                "t-229"
            ],
            "outputs": [
                "t-234"
            ],
            "stats": {
                "cycles": 15456.0,
                "instructions": 8416.0,
                "l1_read": 2656.0,
                "l1_write": 1456.0,
                "llc_access": 301.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 4,
                "start": 335342,
                "end": 335346
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 205, in adadelta\n    acc_delta.mul_(rho).addcmul_(delta, delta, value=1 - rho)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-118",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-236",
                "t-238"
            ],
            "outputs": [
                "t-239"
            ],
            "stats": {
                "cycles": 661600.0,
                "instructions": 1302272.0,
                "l1_read": 395104.0,
                "l1_write": 197928.0,
                "llc_access": 1371.0,
                "microseconds": 225,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 225,
                "start": 335401,
                "end": 335626
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 201, in adadelta\n    square_avg.mul_(rho).addcmul_(grad, grad, value=1 - rho)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-119",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-239",
                "t-56",
                "t-56"
            ],
            "outputs": [
                "t-240"
            ],
            "stats": {
                "cycles": 15744.0,
                "instructions": 9280.0,
                "l1_read": 3152.0,
                "l1_write": 1600.0,
                "llc_access": 181.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 4,
                "start": 335695,
                "end": 335699
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 201, in adadelta\n    square_avg.mul_(rho).addcmul_(grad, grad, value=1 - rho)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-120",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    10,
                    128
                ]
            },
            "inputs": [
                "t-240",
                "t-242"
            ],
            "outputs": [
                "t-243"
            ],
            "stats": {
                "cycles": 670944.0,
                "instructions": 1301152.0,
                "l1_read": 394992.0,
                "l1_write": 198004.0,
                "llc_access": 1448.0,
                "microseconds": 257,
                "flops": 1280.0
            },
            "meta": {},
            "args": [
                1
            ],
            "runtime": {
                "duration": 257,
                "start": 335779,
                "end": 336036
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 202, in adadelta\n    std = square_avg.add(eps).sqrt_()\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-121",
            "optype": "aten::sqrt_",
            "params": {},
            "inputs": [
                "t-243"
            ],
            "outputs": [
                "t-244"
            ],
            "stats": {
                "cycles": 19072.0,
                "instructions": 8864.0,
                "l1_read": 2384.0,
                "l1_write": 1342.0,
                "llc_access": 419.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 4,
                "start": 336095,
                "end": 336099
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 202, in adadelta\n    std = square_avg.add(eps).sqrt_()\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-122",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    10,
                    128
                ]
            },
            "inputs": [
                "t-246",
                "t-222"
            ],
            "outputs": [
                "t-247"
            ],
            "stats": {
                "cycles": 644768.0,
                "instructions": 1301376.0,
                "l1_read": 395136.0,
                "l1_write": 198142.0,
                "llc_access": 1551.0,
                "microseconds": 230,
                "flops": 1280.0
            },
            "meta": {},
            "args": [
                1
            ],
            "runtime": {
                "duration": 230,
                "start": 336174,
                "end": 336404
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-123",
            "optype": "aten::sqrt_",
            "params": {},
            "inputs": [
                "t-247"
            ],
            "outputs": [
                "t-248"
            ],
            "stats": {
                "cycles": 13504.0,
                "instructions": 8832.0,
                "l1_read": 2400.0,
                "l1_write": 1342.0,
                "llc_access": 140.0,
                "microseconds": 3,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 3,
                "start": 336461,
                "end": 336464
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-124",
            "optype": "aten::div_",
            "params": {},
            "inputs": [
                "t-248",
                "t-244"
            ],
            "outputs": [
                "t-249"
            ],
            "stats": {
                "cycles": 14240.0,
                "instructions": 8320.0,
                "l1_read": 2672.0,
                "l1_write": 1470.0,
                "llc_access": 274.0,
                "microseconds": 3,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 3,
                "start": 336523,
                "end": 336526
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-125",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-249",
                "t-56"
            ],
            "outputs": [
                "t-250"
            ],
            "stats": {
                "cycles": 13536.0,
                "instructions": 8288.0,
                "l1_read": 2672.0,
                "l1_write": 1468.0,
                "llc_access": 319.0,
                "microseconds": 3,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 3,
                "start": 336588,
                "end": 336591
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-126",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-26",
                "t-250"
            ],
            "outputs": [
                "t-251"
            ],
            "stats": {
                "cycles": 16288.0,
                "instructions": 8608.0,
                "l1_read": 2848.0,
                "l1_write": 1508.0,
                "llc_access": 338.0,
                "microseconds": 3,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                -1.0
            ],
            "runtime": {
                "duration": 3,
                "start": 336654,
                "end": 336657
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 204, in adadelta\n    param.add_(delta, alpha=-lr)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-127",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-246",
                "t-253"
            ],
            "outputs": [
                "t-254"
            ],
            "stats": {
                "cycles": 649568.0,
                "instructions": 1302848.0,
                "l1_read": 395264.0,
                "l1_write": 198138.0,
                "llc_access": 1566.0,
                "microseconds": 231,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 231,
                "start": 336718,
                "end": 336949
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 205, in adadelta\n    acc_delta.mul_(rho).addcmul_(delta, delta, value=1 - rho)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-128",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-254",
                "t-250",
                "t-250"
            ],
            "outputs": [
                "t-255"
            ],
            "stats": {
                "cycles": 15456.0,
                "instructions": 9280.0,
                "l1_read": 3168.0,
                "l1_write": 1602.0,
                "llc_access": 248.0,
                "microseconds": 3,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 3,
                "start": 337012,
                "end": 337015
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 205, in adadelta\n    acc_delta.mul_(rho).addcmul_(delta, delta, value=1 - rho)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-129",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-257",
                "t-259"
            ],
            "outputs": [
                "t-260"
            ],
            "stats": {
                "cycles": 652736.0,
                "instructions": 1299328.0,
                "l1_read": 394544.0,
                "l1_write": 197694.0,
                "llc_access": 1163.0,
                "microseconds": 209,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 209,
                "start": 337093,
                "end": 337302
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 201, in adadelta\n    square_avg.mul_(rho).addcmul_(grad, grad, value=1 - rho)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-130",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-260",
                "t-52",
                "t-52"
            ],
            "outputs": [
                "t-261"
            ],
            "stats": {
                "cycles": 13600.0,
                "instructions": 8448.0,
                "l1_read": 2640.0,
                "l1_write": 1460.0,
                "llc_access": 99.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 2,
                "start": 337355,
                "end": 337357
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 201, in adadelta\n    square_avg.mul_(rho).addcmul_(grad, grad, value=1 - rho)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-131",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    10
                ]
            },
            "inputs": [
                "t-261",
                "t-263"
            ],
            "outputs": [
                "t-264"
            ],
            "stats": {
                "cycles": 657760.0,
                "instructions": 1304064.0,
                "l1_read": 395568.0,
                "l1_write": 198230.0,
                "llc_access": 1415.0,
                "microseconds": 203,
                "flops": 10.0
            },
            "meta": {},
            "args": [
                1
            ],
            "runtime": {
                "duration": 203,
                "start": 337413,
                "end": 337616
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 202, in adadelta\n    std = square_avg.add(eps).sqrt_()\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-132",
            "optype": "aten::sqrt_",
            "params": {},
            "inputs": [
                "t-264"
            ],
            "outputs": [
                "t-265"
            ],
            "stats": {
                "cycles": 19168.0,
                "instructions": 7296.0,
                "l1_read": 2288.0,
                "l1_write": 1252.0,
                "llc_access": 322.0,
                "microseconds": 3,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 3,
                "start": 337681,
                "end": 337684
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 202, in adadelta\n    std = square_avg.add(eps).sqrt_()\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-133",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    10
                ]
            },
            "inputs": [
                "t-267",
                "t-243"
            ],
            "outputs": [
                "t-268"
            ],
            "stats": {
                "cycles": 657408.0,
                "instructions": 1300000.0,
                "l1_read": 394800.0,
                "l1_write": 197910.0,
                "llc_access": 1226.0,
                "microseconds": 236,
                "flops": 10.0
            },
            "meta": {},
            "args": [
                1
            ],
            "runtime": {
                "duration": 236,
                "start": 337755,
                "end": 337991
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-134",
            "optype": "aten::sqrt_",
            "params": {},
            "inputs": [
                "t-268"
            ],
            "outputs": [
                "t-269"
            ],
            "stats": {
                "cycles": 12480.0,
                "instructions": 7296.0,
                "l1_read": 2288.0,
                "l1_write": 1252.0,
                "llc_access": 133.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 2,
                "start": 338047,
                "end": 338049
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-135",
            "optype": "aten::div_",
            "params": {},
            "inputs": [
                "t-269",
                "t-265"
            ],
            "outputs": [
                "t-270"
            ],
            "stats": {
                "cycles": 12832.0,
                "instructions": 7648.0,
                "l1_read": 2368.0,
                "l1_write": 1320.0,
                "llc_access": 214.0,
                "microseconds": 3,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 3,
                "start": 338105,
                "end": 338108
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-136",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-270",
                "t-52"
            ],
            "outputs": [
                "t-271"
            ],
            "stats": {
                "cycles": 16800.0,
                "instructions": 7776.0,
                "l1_read": 2400.0,
                "l1_write": 1344.0,
                "llc_access": 315.0,
                "microseconds": 3,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 3,
                "start": 338164,
                "end": 338167
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 203, in adadelta\n    delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-137",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-28",
                "t-271"
            ],
            "outputs": [
                "t-272"
            ],
            "stats": {
                "cycles": 15840.0,
                "instructions": 7904.0,
                "l1_read": 2480.0,
                "l1_write": 1360.0,
                "llc_access": 311.0,
                "microseconds": 3,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                -1.0
            ],
            "runtime": {
                "duration": 3,
                "start": 338257,
                "end": 338260
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 204, in adadelta\n    param.add_(delta, alpha=-lr)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-138",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-267",
                "t-274"
            ],
            "outputs": [
                "t-275"
            ],
            "stats": {
                "cycles": 679296.0,
                "instructions": 1304960.0,
                "l1_read": 395456.0,
                "l1_write": 198162.0,
                "llc_access": 1804.0,
                "microseconds": 237,
                "flops": 0.0
            },
            "meta": {},
            "args": [],
            "runtime": {
                "duration": 237,
                "start": 338322,
                "end": 338559
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 205, in adadelta\n    acc_delta.mul_(rho).addcmul_(delta, delta, value=1 - rho)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adadelta.step/op-139",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-275",
                "t-271",
                "t-271"
            ],
            "outputs": [
                "t-276"
            ],
            "stats": {
                "cycles": 15200.0,
                "instructions": 8448.0,
                "l1_read": 2640.0,
                "l1_write": 1460.0,
                "llc_access": 315.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "meta": {},
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 4,
                "start": 338617,
                "end": 338621
            },
            "stack": [
                "  File \"examples/mnist/main.py\", line 153, in <module>\n    main()\n",
                "  File \"examples/mnist/main.py\", line 144, in main\n    train(args, model, device, train_loader, optimizer, epoch)\n",
                "  File \"examples/mnist/main.py\", line 55, in train\n    optimizer.step()\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n    return wrapped(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/adadelta.py\", line 105, in step\n    F.adadelta(params_with_grad,\n",
                "  File \"/home/agur/.conda/envs/ppet/lib/python3.8/site-packages/torch/optim/_functional.py\", line 205, in adadelta\n    acc_delta.mul_(rho).addcmul_(delta, delta, value=1 - rho)\n"
            ]
        }
    ],
    "tensors": {
        "t-7": {
            "name": "t-7",
            "dtype": "FP32",
            "shape": [
                64,
                32,
                26,
                26
            ],
            "strides": [
                21632,
                676,
                26,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 5537792,
            "allocation": 94392926937088,
            "allocation_offset": 0
        },
        "t-2": {
            "name": "t-2",
            "dtype": "FP32",
            "shape": [
                64,
                1,
                28,
                28
            ],
            "strides": [
                784,
                784,
                28,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 200704,
            "allocation": 94392863260672,
            "allocation_offset": 0
        },
        "t-4": {
            "name": "t-4",
            "dtype": "FP32",
            "shape": [
                32,
                1,
                3,
                3
            ],
            "strides": [
                9,
                9,
                3,
                1
            ],
            "version": 4,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 1152,
            "allocation": 94392802269952,
            "allocation_offset": 0
        },
        "t-6": {
            "name": "t-6",
            "dtype": "FP32",
            "shape": [
                32
            ],
            "strides": [
                1
            ],
            "version": 4,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 128,
            "allocation": 94392807980544,
            "allocation_offset": 0
        },
        "t-8": {
            "name": "t-8",
            "dtype": "FP32",
            "shape": [
                64,
                32,
                26,
                26
            ],
            "strides": [
                21632,
                676,
                26,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 5537792,
            "allocation": 94392921399296,
            "allocation_offset": 0
        },
        "t-13": {
            "name": "t-13",
            "dtype": "FP32",
            "shape": [
                64,
                64,
                24,
                24
            ],
            "strides": [
                36864,
                576,
                24,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 9437184,
            "allocation": 94392926937088,
            "allocation_offset": 0
        },
        "t-10": {
            "name": "t-10",
            "dtype": "FP32",
            "shape": [
                64,
                32,
                3,
                3
            ],
            "strides": [
                288,
                9,
                3,
                1
            ],
            "version": 4,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 73728,
            "allocation": 94392800755712,
            "allocation_offset": 0
        },
        "t-12": {
            "name": "t-12",
            "dtype": "FP32",
            "shape": [
                64
            ],
            "strides": [
                1
            ],
            "version": 4,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 256,
            "allocation": 94392770911232,
            "allocation_offset": 0
        },
        "t-14": {
            "name": "t-14",
            "dtype": "FP32",
            "shape": [
                64,
                64,
                24,
                24
            ],
            "strides": [
                36864,
                576,
                24,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 9437184,
            "allocation": 94392833564672,
            "allocation_offset": 0
        },
        "t-15": {
            "name": "t-15",
            "dtype": "FP32",
            "shape": [
                64,
                64,
                12,
                12
            ],
            "strides": [
                9216,
                144,
                12,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 2359296,
            "allocation": 94392822702080,
            "allocation_offset": 0
        },
        "t-16": {
            "name": "t-16",
            "dtype": "FP32",
            "shape": [
                64,
                64,
                12,
                12
            ],
            "strides": [
                9216,
                144,
                12,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 2359296,
            "allocation": 94392934014976,
            "allocation_offset": 0
        },
        "t-17": {
            "name": "t-17",
            "dtype": "FP32",
            "shape": [
                64,
                9216
            ],
            "strides": [
                9216,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 2359296,
            "allocation": 94392934014976,
            "allocation_offset": 0
        },
        "t-22": {
            "name": "t-22",
            "dtype": "FP32",
            "shape": [
                64,
                128
            ],
            "strides": [
                128,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 32768,
            "allocation": 94392807399424,
            "allocation_offset": 0
        },
        "t-19": {
            "name": "t-19",
            "dtype": "FP32",
            "shape": [
                128,
                9216
            ],
            "strides": [
                9216,
                1
            ],
            "version": 4,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 4718592,
            "allocation": 94392817868800,
            "allocation_offset": 0
        },
        "t-21": {
            "name": "t-21",
            "dtype": "FP32",
            "shape": [
                128
            ],
            "strides": [
                1
            ],
            "version": 4,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 512,
            "allocation": 94392807005696,
            "allocation_offset": 0
        },
        "t-23": {
            "name": "t-23",
            "dtype": "FP32",
            "shape": [
                64,
                128
            ],
            "strides": [
                128,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 32768,
            "allocation": 94392803213312,
            "allocation_offset": 0
        },
        "t-24": {
            "name": "t-24",
            "dtype": "FP32",
            "shape": [
                64,
                128
            ],
            "strides": [
                128,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 32768,
            "allocation": 94392803246080,
            "allocation_offset": 0
        },
        "t-29": {
            "name": "t-29",
            "dtype": "FP32",
            "shape": [
                64,
                10
            ],
            "strides": [
                10,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 2560,
            "allocation": 94392802136576,
            "allocation_offset": 0
        },
        "t-26": {
            "name": "t-26",
            "dtype": "FP32",
            "shape": [
                10,
                128
            ],
            "strides": [
                128,
                1
            ],
            "version": 4,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 5120,
            "allocation": 94392817534976,
            "allocation_offset": 0
        },
        "t-28": {
            "name": "t-28",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "strides": [
                1
            ],
            "version": 4,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 40,
            "allocation": 94392802019968,
            "allocation_offset": 0
        },
        "t-30": {
            "name": "t-30",
            "dtype": "FP32",
            "shape": [
                64,
                10
            ],
            "strides": [
                10,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 2560,
            "allocation": 94392802131456,
            "allocation_offset": 0
        },
        "t-33": {
            "name": "t-33",
            "dtype": "FP32",
            "shape": [],
            "strides": [],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 4,
            "allocation": 94392798399680,
            "allocation_offset": 0
        },
        "t-32": {
            "name": "t-32",
            "dtype": "INT64",
            "shape": [
                64
            ],
            "strides": [
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 512,
            "allocation": 94392809273856,
            "allocation_offset": 0
        },
        "t-34": {
            "name": "t-34",
            "dtype": "FP32",
            "shape": [],
            "strides": [],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 4,
            "allocation": 94392798400320,
            "allocation_offset": 0
        },
        "t-37": {
            "name": "t-37",
            "dtype": "FP32",
            "shape": [
                64,
                10
            ],
            "strides": [
                10,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 2560,
            "allocation": 94392822655488,
            "allocation_offset": 0
        },
        "t-36": {
            "name": "t-36",
            "dtype": "FP32",
            "shape": [],
            "strides": [],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 4,
            "allocation": 94392798399744,
            "allocation_offset": 0
        },
        "t-40": {
            "name": "t-40",
            "dtype": "FP32",
            "shape": [
                64,
                10
            ],
            "strides": [
                10,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 2560,
            "allocation": 94392822658048,
            "allocation_offset": 0
        },
        "t-39": {
            "name": "t-39",
            "dtype": "FP32",
            "shape": [
                64,
                10
            ],
            "strides": [
                10,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 2560,
            "allocation": 94392802131456,
            "allocation_offset": 0
        },
        "t-43": {
            "name": "t-43",
            "dtype": "FP32",
            "shape": [
                10,
                128
            ],
            "strides": [
                128,
                1
            ],
            "version": 4,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 5120,
            "allocation": 94392817534976,
            "allocation_offset": 0
        },
        "t-42": {
            "name": "t-42",
            "dtype": "FP32",
            "shape": [
                128,
                10
            ],
            "strides": [
                1,
                128
            ],
            "version": 4,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 5120,
            "allocation": 94392817534976,
            "allocation_offset": 0
        },
        "t-44": {
            "name": "t-44",
            "dtype": "FP32",
            "shape": [
                64,
                128
            ],
            "strides": [
                128,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 32768,
            "allocation": 94392822669312,
            "allocation_offset": 0
        },
        "t-45": {
            "name": "t-45",
            "dtype": "FP32",
            "shape": [
                10,
                64
            ],
            "strides": [
                1,
                10
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 2560,
            "allocation": 94392822658048,
            "allocation_offset": 0
        },
        "t-46": {
            "name": "t-46",
            "dtype": "FP32",
            "shape": [
                10,
                128
            ],
            "strides": [
                128,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 5120,
            "allocation": 94392863192064,
            "allocation_offset": 0
        },
        "t-47": {
            "name": "t-47",
            "dtype": "FP32",
            "shape": [
                128,
                10
            ],
            "strides": [
                1,
                128
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 5120,
            "allocation": 94392863192064,
            "allocation_offset": 0
        },
        "t-48": {
            "name": "t-48",
            "dtype": "FP32",
            "shape": [
                1,
                10
            ],
            "strides": [
                10,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 40,
            "allocation": 94392798402048,
            "allocation_offset": 0
        },
        "t-49": {
            "name": "t-49",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "strides": [
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 40,
            "allocation": 94392798402048,
            "allocation_offset": 0
        },
        "t-52": {
            "name": "t-52",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "strides": [
                1
            ],
            "version": 6,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 40,
            "allocation": 94392802020224,
            "allocation_offset": 0
        },
        "t-51": {
            "name": "t-51",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "strides": [
                1
            ],
            "version": 5,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 40,
            "allocation": 94392802020224,
            "allocation_offset": 0
        },
        "t-53": {
            "name": "t-53",
            "dtype": "FP32",
            "shape": [
                10,
                128
            ],
            "strides": [
                128,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 5120,
            "allocation": 94392863192064,
            "allocation_offset": 0
        },
        "t-56": {
            "name": "t-56",
            "dtype": "FP32",
            "shape": [
                10,
                128
            ],
            "strides": [
                128,
                1
            ],
            "version": 6,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 5120,
            "allocation": 94392803155968,
            "allocation_offset": 0
        },
        "t-55": {
            "name": "t-55",
            "dtype": "FP32",
            "shape": [
                10,
                128
            ],
            "strides": [
                128,
                1
            ],
            "version": 5,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 5120,
            "allocation": 94392803155968,
            "allocation_offset": 0
        },
        "t-59": {
            "name": "t-59",
            "dtype": "FP32",
            "shape": [
                64,
                128
            ],
            "strides": [
                128,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 32768,
            "allocation": 94392803246080,
            "allocation_offset": 0
        },
        "t-58": {
            "name": "t-58",
            "dtype": "FP32",
            "shape": [
                64,
                128
            ],
            "strides": [
                128,
                1
            ],
            "version": 2,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 32768,
            "allocation": 94392807399424,
            "allocation_offset": 0
        },
        "t-62": {
            "name": "t-62",
            "dtype": "FP32",
            "shape": [
                64,
                128
            ],
            "strides": [
                128,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 32768,
            "allocation": 94392807399424,
            "allocation_offset": 0
        },
        "t-61": {
            "name": "t-61",
            "dtype": "FP32",
            "shape": [
                64,
                128
            ],
            "strides": [
                128,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 32768,
            "allocation": 94392803213312,
            "allocation_offset": 0
        },
        "t-65": {
            "name": "t-65",
            "dtype": "FP32",
            "shape": [
                128,
                9216
            ],
            "strides": [
                9216,
                1
            ],
            "version": 4,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 4718592,
            "allocation": 94392817868800,
            "allocation_offset": 0
        },
        "t-64": {
            "name": "t-64",
            "dtype": "FP32",
            "shape": [
                9216,
                128
            ],
            "strides": [
                1,
                9216
            ],
            "version": 4,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 4718592,
            "allocation": 94392817868800,
            "allocation_offset": 0
        },
        "t-66": {
            "name": "t-66",
            "dtype": "FP32",
            "shape": [
                64,
                9216
            ],
            "strides": [
                9216,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 2359296,
            "allocation": 94392822702080,
            "allocation_offset": 0
        },
        "t-67": {
            "name": "t-67",
            "dtype": "FP32",
            "shape": [
                128,
                64
            ],
            "strides": [
                1,
                128
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 32768,
            "allocation": 94392807399424,
            "allocation_offset": 0
        },
        "t-68": {
            "name": "t-68",
            "dtype": "FP32",
            "shape": [
                128,
                9216
            ],
            "strides": [
                9216,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 4718592,
            "allocation": 94392843001856,
            "allocation_offset": 0
        },
        "t-69": {
            "name": "t-69",
            "dtype": "FP32",
            "shape": [
                9216,
                128
            ],
            "strides": [
                1,
                9216
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 4718592,
            "allocation": 94392843001856,
            "allocation_offset": 0
        },
        "t-70": {
            "name": "t-70",
            "dtype": "FP32",
            "shape": [
                1,
                128
            ],
            "strides": [
                128,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 512,
            "allocation": 94392809271808,
            "allocation_offset": 0
        },
        "t-71": {
            "name": "t-71",
            "dtype": "FP32",
            "shape": [
                128
            ],
            "strides": [
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 512,
            "allocation": 94392809271808,
            "allocation_offset": 0
        },
        "t-74": {
            "name": "t-74",
            "dtype": "FP32",
            "shape": [
                128
            ],
            "strides": [
                1
            ],
            "version": 6,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 512,
            "allocation": 94392809268736,
            "allocation_offset": 0
        },
        "t-73": {
            "name": "t-73",
            "dtype": "FP32",
            "shape": [
                128
            ],
            "strides": [
                1
            ],
            "version": 5,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 512,
            "allocation": 94392809268736,
            "allocation_offset": 0
        },
        "t-75": {
            "name": "t-75",
            "dtype": "FP32",
            "shape": [
                128,
                9216
            ],
            "strides": [
                9216,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 4718592,
            "allocation": 94392843001856,
            "allocation_offset": 0
        },
        "t-78": {
            "name": "t-78",
            "dtype": "FP32",
            "shape": [
                128,
                9216
            ],
            "strides": [
                9216,
                1
            ],
            "version": 6,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 4718592,
            "allocation": 94392857976832,
            "allocation_offset": 0
        },
        "t-77": {
            "name": "t-77",
            "dtype": "FP32",
            "shape": [
                128,
                9216
            ],
            "strides": [
                9216,
                1
            ],
            "version": 5,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 4718592,
            "allocation": 94392857976832,
            "allocation_offset": 0
        },
        "t-79": {
            "name": "t-79",
            "dtype": "FP32",
            "shape": [
                64,
                64,
                12,
                12
            ],
            "strides": [
                9216,
                144,
                12,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 2359296,
            "allocation": 94392822702080,
            "allocation_offset": 0
        },
        "t-82": {
            "name": "t-82",
            "dtype": "FP32",
            "shape": [
                64,
                64,
                12,
                12
            ],
            "strides": [
                9216,
                144,
                12,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 2359296,
            "allocation": 94392934014976,
            "allocation_offset": 0
        },
        "t-81": {
            "name": "t-81",
            "dtype": "FP32",
            "shape": [
                64,
                64,
                12,
                12
            ],
            "strides": [
                9216,
                144,
                12,
                1
            ],
            "version": 2,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 2359296,
            "allocation": 94392931655680,
            "allocation_offset": 0
        },
        "t-85": {
            "name": "t-85",
            "dtype": "FP32",
            "shape": [
                64,
                64,
                24,
                24
            ],
            "strides": [
                36864,
                576,
                24,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 9437184,
            "allocation": 94392843001856,
            "allocation_offset": 0
        },
        "t-84": {
            "name": "t-84",
            "dtype": "INT64",
            "shape": [
                64,
                64,
                12,
                12
            ],
            "strides": [
                9216,
                144,
                12,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 4718592,
            "allocation": 94392926937088,
            "allocation_offset": 0
        },
        "t-86": {
            "name": "t-86",
            "dtype": "FP32",
            "shape": [
                64,
                64,
                24,
                24
            ],
            "strides": [
                36864,
                576,
                24,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 9437184,
            "allocation": 94392926937088,
            "allocation_offset": 0
        },
        "t-87": {
            "name": "t-87",
            "dtype": "FP32",
            "shape": [
                64,
                32,
                26,
                26
            ],
            "strides": [
                21632,
                676,
                26,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 5537792,
            "allocation": 94392833564672,
            "allocation_offset": 0
        },
        "t-88": {
            "name": "t-88",
            "dtype": "FP32",
            "shape": [
                64,
                32,
                3,
                3
            ],
            "strides": [
                288,
                9,
                3,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 73728,
            "allocation": 94392863039488,
            "allocation_offset": 0
        },
        "t-89": {
            "name": "t-89",
            "dtype": "FP32",
            "shape": [
                64
            ],
            "strides": [
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 256,
            "allocation": 94392772574464,
            "allocation_offset": 0
        },
        "t-92": {
            "name": "t-92",
            "dtype": "FP32",
            "shape": [
                64,
                32,
                3,
                3
            ],
            "strides": [
                288,
                9,
                3,
                1
            ],
            "version": 6,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 73728,
            "allocation": 94392862810112,
            "allocation_offset": 0
        },
        "t-91": {
            "name": "t-91",
            "dtype": "FP32",
            "shape": [
                64,
                32,
                3,
                3
            ],
            "strides": [
                288,
                9,
                3,
                1
            ],
            "version": 5,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 73728,
            "allocation": 94392862810112,
            "allocation_offset": 0
        },
        "t-95": {
            "name": "t-95",
            "dtype": "FP32",
            "shape": [
                64
            ],
            "strides": [
                1
            ],
            "version": 6,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 256,
            "allocation": 94392772774400,
            "allocation_offset": 0
        },
        "t-94": {
            "name": "t-94",
            "dtype": "FP32",
            "shape": [
                64
            ],
            "strides": [
                1
            ],
            "version": 5,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 256,
            "allocation": 94392772774400,
            "allocation_offset": 0
        },
        "t-98": {
            "name": "t-98",
            "dtype": "FP32",
            "shape": [
                64,
                32,
                26,
                26
            ],
            "strides": [
                21632,
                676,
                26,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 5537792,
            "allocation": 94392926937088,
            "allocation_offset": 0
        },
        "t-97": {
            "name": "t-97",
            "dtype": "FP32",
            "shape": [
                64,
                32,
                26,
                26
            ],
            "strides": [
                21632,
                676,
                26,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 5537792,
            "allocation": 94392921399296,
            "allocation_offset": 0
        },
        "t-99": {
            "name": "t-99",
            "dtype": "FP32",
            "shape": [
                32,
                1,
                3,
                3
            ],
            "strides": [
                9,
                9,
                3,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 1152,
            "allocation": 94392802278016,
            "allocation_offset": 0
        },
        "t-100": {
            "name": "t-100",
            "dtype": "FP32",
            "shape": [
                32
            ],
            "strides": [
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 128,
            "allocation": 94392803105792,
            "allocation_offset": 0
        },
        "t-103": {
            "name": "t-103",
            "dtype": "FP32",
            "shape": [
                32,
                1,
                3,
                3
            ],
            "strides": [
                9,
                9,
                3,
                1
            ],
            "version": 6,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 1152,
            "allocation": 94392802274560,
            "allocation_offset": 0
        },
        "t-102": {
            "name": "t-102",
            "dtype": "FP32",
            "shape": [
                32,
                1,
                3,
                3
            ],
            "strides": [
                9,
                9,
                3,
                1
            ],
            "version": 5,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 1152,
            "allocation": 94392802274560,
            "allocation_offset": 0
        },
        "t-106": {
            "name": "t-106",
            "dtype": "FP32",
            "shape": [
                32
            ],
            "strides": [
                1
            ],
            "version": 6,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 128,
            "allocation": 94392803103488,
            "allocation_offset": 0
        },
        "t-105": {
            "name": "t-105",
            "dtype": "FP32",
            "shape": [
                32
            ],
            "strides": [
                1
            ],
            "version": 5,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 128,
            "allocation": 94392803103488,
            "allocation_offset": 0
        },
        "t-107": {
            "name": "t-107",
            "dtype": "FP32",
            "shape": [
                1
            ],
            "strides": [
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 4,
            "allocation": 94392763258624,
            "allocation_offset": 0
        },
        "t-108": {
            "name": "t-108",
            "dtype": "UINT8",
            "shape": [
                16
            ],
            "strides": [
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 16,
            "allocation": 94392763258560,
            "allocation_offset": 0
        },
        "t-111": {
            "name": "t-111",
            "dtype": "FP32",
            "shape": [
                32,
                1,
                3,
                3
            ],
            "strides": [
                9,
                9,
                3,
                1
            ],
            "version": 7,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 1152,
            "allocation": 94392802275712,
            "allocation_offset": 0
        },
        "t-110": {
            "name": "t-110",
            "dtype": "FP32",
            "shape": [
                32,
                1,
                3,
                3
            ],
            "strides": [
                9,
                9,
                3,
                1
            ],
            "version": 6,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 1152,
            "allocation": 94392802275712,
            "allocation_offset": 0
        },
        "t-112": {
            "name": "t-112",
            "dtype": "FP32",
            "shape": [
                32,
                1,
                3,
                3
            ],
            "strides": [
                9,
                9,
                3,
                1
            ],
            "version": 8,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 1152,
            "allocation": 94392802275712,
            "allocation_offset": 0
        },
        "t-115": {
            "name": "t-115",
            "dtype": "FP32",
            "shape": [
                32,
                1,
                3,
                3
            ],
            "strides": [
                9,
                9,
                3,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 1152,
            "allocation": 94392863024256,
            "allocation_offset": 0
        },
        "t-114": {
            "name": "t-114",
            "dtype": "FP64",
            "shape": [],
            "strides": [],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 8,
            "allocation": 94392763258624,
            "allocation_offset": 0
        },
        "t-116": {
            "name": "t-116",
            "dtype": "FP32",
            "shape": [
                32,
                1,
                3,
                3
            ],
            "strides": [
                9,
                9,
                3,
                1
            ],
            "version": 1,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 1152,
            "allocation": 94392863024256,
            "allocation_offset": 0
        },
        "t-121": {
            "name": "t-121",
            "dtype": "FP32",
            "shape": [
                32,
                1,
                3,
                3
            ],
            "strides": [
                9,
                9,
                3,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 1152,
            "allocation": 94392863025408,
            "allocation_offset": 0
        },
        "t-118": {
            "name": "t-118",
            "dtype": "FP32",
            "shape": [
                32,
                1,
                3,
                3
            ],
            "strides": [
                9,
                9,
                3,
                1
            ],
            "version": 6,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 1152,
            "allocation": 94392802276864,
            "allocation_offset": 0
        },
        "t-120": {
            "name": "t-120",
            "dtype": "FP64",
            "shape": [],
            "strides": [],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 8,
            "allocation": 94392763258624,
            "allocation_offset": 0
        },
        "t-122": {
            "name": "t-122",
            "dtype": "FP32",
            "shape": [
                32,
                1,
                3,
                3
            ],
            "strides": [
                9,
                9,
                3,
                1
            ],
            "version": 1,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 1152,
            "allocation": 94392863025408,
            "allocation_offset": 0
        },
        "t-123": {
            "name": "t-123",
            "dtype": "FP32",
            "shape": [
                32,
                1,
                3,
                3
            ],
            "strides": [
                9,
                9,
                3,
                1
            ],
            "version": 2,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 1152,
            "allocation": 94392863025408,
            "allocation_offset": 0
        },
        "t-124": {
            "name": "t-124",
            "dtype": "FP32",
            "shape": [
                32,
                1,
                3,
                3
            ],
            "strides": [
                9,
                9,
                3,
                1
            ],
            "version": 3,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 1152,
            "allocation": 94392863025408,
            "allocation_offset": 0
        },
        "t-125": {
            "name": "t-125",
            "dtype": "FP32",
            "shape": [
                32,
                1,
                3,
                3
            ],
            "strides": [
                9,
                9,
                3,
                1
            ],
            "version": 5,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 1152,
            "allocation": 94392802269952,
            "allocation_offset": 0
        },
        "t-128": {
            "name": "t-128",
            "dtype": "FP32",
            "shape": [
                32,
                1,
                3,
                3
            ],
            "strides": [
                9,
                9,
                3,
                1
            ],
            "version": 7,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 1152,
            "allocation": 94392802276864,
            "allocation_offset": 0
        },
        "t-127": {
            "name": "t-127",
            "dtype": "FP64",
            "shape": [],
            "strides": [],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 8,
            "allocation": 94392863514688,
            "allocation_offset": 0
        },
        "t-129": {
            "name": "t-129",
            "dtype": "FP32",
            "shape": [
                32,
                1,
                3,
                3
            ],
            "strides": [
                9,
                9,
                3,
                1
            ],
            "version": 8,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 1152,
            "allocation": 94392802276864,
            "allocation_offset": 0
        },
        "t-134": {
            "name": "t-134",
            "dtype": "FP32",
            "shape": [
                32
            ],
            "strides": [
                1
            ],
            "version": 7,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 128,
            "allocation": 94392803102976,
            "allocation_offset": 0
        },
        "t-131": {
            "name": "t-131",
            "dtype": "FP32",
            "shape": [
                32
            ],
            "strides": [
                1
            ],
            "version": 6,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 128,
            "allocation": 94392803102976,
            "allocation_offset": 0
        },
        "t-133": {
            "name": "t-133",
            "dtype": "FP64",
            "shape": [],
            "strides": [],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 8,
            "allocation": 94392863514688,
            "allocation_offset": 0
        },
        "t-135": {
            "name": "t-135",
            "dtype": "FP32",
            "shape": [
                32
            ],
            "strides": [
                1
            ],
            "version": 8,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 128,
            "allocation": 94392803102976,
            "allocation_offset": 0
        },
        "t-138": {
            "name": "t-138",
            "dtype": "FP32",
            "shape": [
                32
            ],
            "strides": [
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 128,
            "allocation": 94392803105792,
            "allocation_offset": 0
        },
        "t-137": {
            "name": "t-137",
            "dtype": "FP64",
            "shape": [],
            "strides": [],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 8,
            "allocation": 94392863514688,
            "allocation_offset": 0
        },
        "t-139": {
            "name": "t-139",
            "dtype": "FP32",
            "shape": [
                32
            ],
            "strides": [
                1
            ],
            "version": 1,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 128,
            "allocation": 94392803105792,
            "allocation_offset": 0
        },
        "t-142": {
            "name": "t-142",
            "dtype": "FP32",
            "shape": [
                32
            ],
            "strides": [
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 128,
            "allocation": 94392803105408,
            "allocation_offset": 0
        },
        "t-141": {
            "name": "t-141",
            "dtype": "FP32",
            "shape": [
                32
            ],
            "strides": [
                1
            ],
            "version": 6,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 128,
            "allocation": 94392803104128,
            "allocation_offset": 0
        },
        "t-143": {
            "name": "t-143",
            "dtype": "FP32",
            "shape": [
                32
            ],
            "strides": [
                1
            ],
            "version": 1,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 128,
            "allocation": 94392803105408,
            "allocation_offset": 0
        },
        "t-144": {
            "name": "t-144",
            "dtype": "FP32",
            "shape": [
                32
            ],
            "strides": [
                1
            ],
            "version": 2,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 128,
            "allocation": 94392803105408,
            "allocation_offset": 0
        },
        "t-145": {
            "name": "t-145",
            "dtype": "FP32",
            "shape": [
                32
            ],
            "strides": [
                1
            ],
            "version": 3,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 128,
            "allocation": 94392803105408,
            "allocation_offset": 0
        },
        "t-146": {
            "name": "t-146",
            "dtype": "FP32",
            "shape": [
                32
            ],
            "strides": [
                1
            ],
            "version": 5,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 128,
            "allocation": 94392807980544,
            "allocation_offset": 0
        },
        "t-149": {
            "name": "t-149",
            "dtype": "FP32",
            "shape": [
                32
            ],
            "strides": [
                1
            ],
            "version": 7,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 128,
            "allocation": 94392803104128,
            "allocation_offset": 0
        },
        "t-148": {
            "name": "t-148",
            "dtype": "FP64",
            "shape": [],
            "strides": [],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 8,
            "allocation": 94392863516928,
            "allocation_offset": 0
        },
        "t-150": {
            "name": "t-150",
            "dtype": "FP32",
            "shape": [
                32
            ],
            "strides": [
                1
            ],
            "version": 8,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 128,
            "allocation": 94392803104128,
            "allocation_offset": 0
        },
        "t-155": {
            "name": "t-155",
            "dtype": "FP32",
            "shape": [
                64,
                32,
                3,
                3
            ],
            "strides": [
                288,
                9,
                3,
                1
            ],
            "version": 7,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 73728,
            "allocation": 94392812716032,
            "allocation_offset": 0
        },
        "t-152": {
            "name": "t-152",
            "dtype": "FP32",
            "shape": [
                64,
                32,
                3,
                3
            ],
            "strides": [
                288,
                9,
                3,
                1
            ],
            "version": 6,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 73728,
            "allocation": 94392812716032,
            "allocation_offset": 0
        },
        "t-154": {
            "name": "t-154",
            "dtype": "FP64",
            "shape": [],
            "strides": [],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 8,
            "allocation": 94392863516928,
            "allocation_offset": 0
        },
        "t-156": {
            "name": "t-156",
            "dtype": "FP32",
            "shape": [
                64,
                32,
                3,
                3
            ],
            "strides": [
                288,
                9,
                3,
                1
            ],
            "version": 8,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 73728,
            "allocation": 94392812716032,
            "allocation_offset": 0
        },
        "t-159": {
            "name": "t-159",
            "dtype": "FP32",
            "shape": [
                64,
                32,
                3,
                3
            ],
            "strides": [
                288,
                9,
                3,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 73728,
            "allocation": 94392863039488,
            "allocation_offset": 0
        },
        "t-158": {
            "name": "t-158",
            "dtype": "FP64",
            "shape": [],
            "strides": [],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 8,
            "allocation": 94392863516928,
            "allocation_offset": 0
        },
        "t-160": {
            "name": "t-160",
            "dtype": "FP32",
            "shape": [
                64,
                32,
                3,
                3
            ],
            "strides": [
                288,
                9,
                3,
                1
            ],
            "version": 1,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 73728,
            "allocation": 94392863039488,
            "allocation_offset": 0
        },
        "t-163": {
            "name": "t-163",
            "dtype": "FP32",
            "shape": [
                64,
                32,
                3,
                3
            ],
            "strides": [
                288,
                9,
                3,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 73728,
            "allocation": 94392863113216,
            "allocation_offset": 0
        },
        "t-162": {
            "name": "t-162",
            "dtype": "FP32",
            "shape": [
                64,
                32,
                3,
                3
            ],
            "strides": [
                288,
                9,
                3,
                1
            ],
            "version": 6,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 73728,
            "allocation": 94392862949376,
            "allocation_offset": 0
        },
        "t-164": {
            "name": "t-164",
            "dtype": "FP32",
            "shape": [
                64,
                32,
                3,
                3
            ],
            "strides": [
                288,
                9,
                3,
                1
            ],
            "version": 1,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 73728,
            "allocation": 94392863113216,
            "allocation_offset": 0
        },
        "t-165": {
            "name": "t-165",
            "dtype": "FP32",
            "shape": [
                64,
                32,
                3,
                3
            ],
            "strides": [
                288,
                9,
                3,
                1
            ],
            "version": 2,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 73728,
            "allocation": 94392863113216,
            "allocation_offset": 0
        },
        "t-166": {
            "name": "t-166",
            "dtype": "FP32",
            "shape": [
                64,
                32,
                3,
                3
            ],
            "strides": [
                288,
                9,
                3,
                1
            ],
            "version": 3,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 73728,
            "allocation": 94392863113216,
            "allocation_offset": 0
        },
        "t-167": {
            "name": "t-167",
            "dtype": "FP32",
            "shape": [
                64,
                32,
                3,
                3
            ],
            "strides": [
                288,
                9,
                3,
                1
            ],
            "version": 5,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 73728,
            "allocation": 94392800755712,
            "allocation_offset": 0
        },
        "t-170": {
            "name": "t-170",
            "dtype": "FP32",
            "shape": [
                64,
                32,
                3,
                3
            ],
            "strides": [
                288,
                9,
                3,
                1
            ],
            "version": 7,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 73728,
            "allocation": 94392862949376,
            "allocation_offset": 0
        },
        "t-169": {
            "name": "t-169",
            "dtype": "FP64",
            "shape": [],
            "strides": [],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 8,
            "allocation": 94392863519168,
            "allocation_offset": 0
        },
        "t-171": {
            "name": "t-171",
            "dtype": "FP32",
            "shape": [
                64,
                32,
                3,
                3
            ],
            "strides": [
                288,
                9,
                3,
                1
            ],
            "version": 8,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 73728,
            "allocation": 94392862949376,
            "allocation_offset": 0
        },
        "t-176": {
            "name": "t-176",
            "dtype": "FP32",
            "shape": [
                64
            ],
            "strides": [
                1
            ],
            "version": 7,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 256,
            "allocation": 94392767332608,
            "allocation_offset": 0
        },
        "t-173": {
            "name": "t-173",
            "dtype": "FP32",
            "shape": [
                64
            ],
            "strides": [
                1
            ],
            "version": 6,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 256,
            "allocation": 94392767332608,
            "allocation_offset": 0
        },
        "t-175": {
            "name": "t-175",
            "dtype": "FP64",
            "shape": [],
            "strides": [],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 8,
            "allocation": 94392863519168,
            "allocation_offset": 0
        },
        "t-177": {
            "name": "t-177",
            "dtype": "FP32",
            "shape": [
                64
            ],
            "strides": [
                1
            ],
            "version": 8,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 256,
            "allocation": 94392767332608,
            "allocation_offset": 0
        },
        "t-180": {
            "name": "t-180",
            "dtype": "FP32",
            "shape": [
                64
            ],
            "strides": [
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 256,
            "allocation": 94392772574464,
            "allocation_offset": 0
        },
        "t-179": {
            "name": "t-179",
            "dtype": "FP64",
            "shape": [],
            "strides": [],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 8,
            "allocation": 94392863519168,
            "allocation_offset": 0
        },
        "t-181": {
            "name": "t-181",
            "dtype": "FP32",
            "shape": [
                64
            ],
            "strides": [
                1
            ],
            "version": 1,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 256,
            "allocation": 94392772574464,
            "allocation_offset": 0
        },
        "t-184": {
            "name": "t-184",
            "dtype": "FP32",
            "shape": [
                64
            ],
            "strides": [
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 256,
            "allocation": 94392771296768,
            "allocation_offset": 0
        },
        "t-183": {
            "name": "t-183",
            "dtype": "FP32",
            "shape": [
                64
            ],
            "strides": [
                1
            ],
            "version": 6,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 256,
            "allocation": 94392772774656,
            "allocation_offset": 0
        },
        "t-185": {
            "name": "t-185",
            "dtype": "FP32",
            "shape": [
                64
            ],
            "strides": [
                1
            ],
            "version": 1,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 256,
            "allocation": 94392771296768,
            "allocation_offset": 0
        },
        "t-186": {
            "name": "t-186",
            "dtype": "FP32",
            "shape": [
                64
            ],
            "strides": [
                1
            ],
            "version": 2,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 256,
            "allocation": 94392771296768,
            "allocation_offset": 0
        },
        "t-187": {
            "name": "t-187",
            "dtype": "FP32",
            "shape": [
                64
            ],
            "strides": [
                1
            ],
            "version": 3,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 256,
            "allocation": 94392771296768,
            "allocation_offset": 0
        },
        "t-188": {
            "name": "t-188",
            "dtype": "FP32",
            "shape": [
                64
            ],
            "strides": [
                1
            ],
            "version": 5,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 256,
            "allocation": 94392770911232,
            "allocation_offset": 0
        },
        "t-191": {
            "name": "t-191",
            "dtype": "FP32",
            "shape": [
                64
            ],
            "strides": [
                1
            ],
            "version": 7,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 256,
            "allocation": 94392772774656,
            "allocation_offset": 0
        },
        "t-190": {
            "name": "t-190",
            "dtype": "FP64",
            "shape": [],
            "strides": [],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 8,
            "allocation": 94392863521408,
            "allocation_offset": 0
        },
        "t-192": {
            "name": "t-192",
            "dtype": "FP32",
            "shape": [
                64
            ],
            "strides": [
                1
            ],
            "version": 8,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 256,
            "allocation": 94392772774656,
            "allocation_offset": 0
        },
        "t-197": {
            "name": "t-197",
            "dtype": "FP32",
            "shape": [
                128,
                9216
            ],
            "strides": [
                9216,
                1
            ],
            "version": 7,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 4718592,
            "allocation": 94392911962112,
            "allocation_offset": 0
        },
        "t-194": {
            "name": "t-194",
            "dtype": "FP32",
            "shape": [
                128,
                9216
            ],
            "strides": [
                9216,
                1
            ],
            "version": 6,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 4718592,
            "allocation": 94392911962112,
            "allocation_offset": 0
        },
        "t-196": {
            "name": "t-196",
            "dtype": "FP64",
            "shape": [],
            "strides": [],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 8,
            "allocation": 94392863521408,
            "allocation_offset": 0
        },
        "t-198": {
            "name": "t-198",
            "dtype": "FP32",
            "shape": [
                128,
                9216
            ],
            "strides": [
                9216,
                1
            ],
            "version": 8,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 4718592,
            "allocation": 94392911962112,
            "allocation_offset": 0
        },
        "t-201": {
            "name": "t-201",
            "dtype": "FP32",
            "shape": [
                128,
                9216
            ],
            "strides": [
                9216,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 4718592,
            "allocation": 94392921399296,
            "allocation_offset": 0
        },
        "t-200": {
            "name": "t-200",
            "dtype": "FP64",
            "shape": [],
            "strides": [],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 8,
            "allocation": 94392863521408,
            "allocation_offset": 0
        },
        "t-202": {
            "name": "t-202",
            "dtype": "FP32",
            "shape": [
                128,
                9216
            ],
            "strides": [
                9216,
                1
            ],
            "version": 1,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 4718592,
            "allocation": 94392921399296,
            "allocation_offset": 0
        },
        "t-205": {
            "name": "t-205",
            "dtype": "FP32",
            "shape": [
                128,
                9216
            ],
            "strides": [
                9216,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 4718592,
            "allocation": 94392926117888,
            "allocation_offset": 0
        },
        "t-204": {
            "name": "t-204",
            "dtype": "FP32",
            "shape": [
                128,
                9216
            ],
            "strides": [
                9216,
                1
            ],
            "version": 6,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 4718592,
            "allocation": 94392916680704,
            "allocation_offset": 0
        },
        "t-206": {
            "name": "t-206",
            "dtype": "FP32",
            "shape": [
                128,
                9216
            ],
            "strides": [
                9216,
                1
            ],
            "version": 1,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 4718592,
            "allocation": 94392926117888,
            "allocation_offset": 0
        },
        "t-207": {
            "name": "t-207",
            "dtype": "FP32",
            "shape": [
                128,
                9216
            ],
            "strides": [
                9216,
                1
            ],
            "version": 2,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 4718592,
            "allocation": 94392926117888,
            "allocation_offset": 0
        },
        "t-208": {
            "name": "t-208",
            "dtype": "FP32",
            "shape": [
                128,
                9216
            ],
            "strides": [
                9216,
                1
            ],
            "version": 3,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 4718592,
            "allocation": 94392926117888,
            "allocation_offset": 0
        },
        "t-209": {
            "name": "t-209",
            "dtype": "FP32",
            "shape": [
                128,
                9216
            ],
            "strides": [
                9216,
                1
            ],
            "version": 5,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 4718592,
            "allocation": 94392817868800,
            "allocation_offset": 0
        },
        "t-212": {
            "name": "t-212",
            "dtype": "FP32",
            "shape": [
                128,
                9216
            ],
            "strides": [
                9216,
                1
            ],
            "version": 7,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 4718592,
            "allocation": 94392916680704,
            "allocation_offset": 0
        },
        "t-211": {
            "name": "t-211",
            "dtype": "FP64",
            "shape": [],
            "strides": [],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 8,
            "allocation": 94392863720256,
            "allocation_offset": 0
        },
        "t-213": {
            "name": "t-213",
            "dtype": "FP32",
            "shape": [
                128,
                9216
            ],
            "strides": [
                9216,
                1
            ],
            "version": 8,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 4718592,
            "allocation": 94392916680704,
            "allocation_offset": 0
        },
        "t-218": {
            "name": "t-218",
            "dtype": "FP32",
            "shape": [
                128
            ],
            "strides": [
                1
            ],
            "version": 7,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 512,
            "allocation": 94392809269248,
            "allocation_offset": 0
        },
        "t-215": {
            "name": "t-215",
            "dtype": "FP32",
            "shape": [
                128
            ],
            "strides": [
                1
            ],
            "version": 6,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 512,
            "allocation": 94392809269248,
            "allocation_offset": 0
        },
        "t-217": {
            "name": "t-217",
            "dtype": "FP64",
            "shape": [],
            "strides": [],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 8,
            "allocation": 94392863720256,
            "allocation_offset": 0
        },
        "t-219": {
            "name": "t-219",
            "dtype": "FP32",
            "shape": [
                128
            ],
            "strides": [
                1
            ],
            "version": 8,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 512,
            "allocation": 94392809269248,
            "allocation_offset": 0
        },
        "t-222": {
            "name": "t-222",
            "dtype": "FP32",
            "shape": [
                128
            ],
            "strides": [
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 512,
            "allocation": 94392809272832,
            "allocation_offset": 0
        },
        "t-221": {
            "name": "t-221",
            "dtype": "FP64",
            "shape": [],
            "strides": [],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 8,
            "allocation": 94392863720256,
            "allocation_offset": 0
        },
        "t-223": {
            "name": "t-223",
            "dtype": "FP32",
            "shape": [
                128
            ],
            "strides": [
                1
            ],
            "version": 1,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 512,
            "allocation": 94392809272832,
            "allocation_offset": 0
        },
        "t-226": {
            "name": "t-226",
            "dtype": "FP32",
            "shape": [
                128
            ],
            "strides": [
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 512,
            "allocation": 94392809273344,
            "allocation_offset": 0
        },
        "t-225": {
            "name": "t-225",
            "dtype": "FP32",
            "shape": [
                128
            ],
            "strides": [
                1
            ],
            "version": 6,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 512,
            "allocation": 94392809269760,
            "allocation_offset": 0
        },
        "t-227": {
            "name": "t-227",
            "dtype": "FP32",
            "shape": [
                128
            ],
            "strides": [
                1
            ],
            "version": 1,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 512,
            "allocation": 94392809273344,
            "allocation_offset": 0
        },
        "t-228": {
            "name": "t-228",
            "dtype": "FP32",
            "shape": [
                128
            ],
            "strides": [
                1
            ],
            "version": 2,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 512,
            "allocation": 94392809273344,
            "allocation_offset": 0
        },
        "t-229": {
            "name": "t-229",
            "dtype": "FP32",
            "shape": [
                128
            ],
            "strides": [
                1
            ],
            "version": 3,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 512,
            "allocation": 94392809273344,
            "allocation_offset": 0
        },
        "t-230": {
            "name": "t-230",
            "dtype": "FP32",
            "shape": [
                128
            ],
            "strides": [
                1
            ],
            "version": 5,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 512,
            "allocation": 94392807005696,
            "allocation_offset": 0
        },
        "t-233": {
            "name": "t-233",
            "dtype": "FP32",
            "shape": [
                128
            ],
            "strides": [
                1
            ],
            "version": 7,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 512,
            "allocation": 94392809269760,
            "allocation_offset": 0
        },
        "t-232": {
            "name": "t-232",
            "dtype": "FP64",
            "shape": [],
            "strides": [],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 8,
            "allocation": 94392863722496,
            "allocation_offset": 0
        },
        "t-234": {
            "name": "t-234",
            "dtype": "FP32",
            "shape": [
                128
            ],
            "strides": [
                1
            ],
            "version": 8,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 512,
            "allocation": 94392809269760,
            "allocation_offset": 0
        },
        "t-239": {
            "name": "t-239",
            "dtype": "FP32",
            "shape": [
                10,
                128
            ],
            "strides": [
                128,
                1
            ],
            "version": 7,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 5120,
            "allocation": 94392803166208,
            "allocation_offset": 0
        },
        "t-236": {
            "name": "t-236",
            "dtype": "FP32",
            "shape": [
                10,
                128
            ],
            "strides": [
                128,
                1
            ],
            "version": 6,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 5120,
            "allocation": 94392803166208,
            "allocation_offset": 0
        },
        "t-238": {
            "name": "t-238",
            "dtype": "FP64",
            "shape": [],
            "strides": [],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 8,
            "allocation": 94392863722496,
            "allocation_offset": 0
        },
        "t-240": {
            "name": "t-240",
            "dtype": "FP32",
            "shape": [
                10,
                128
            ],
            "strides": [
                128,
                1
            ],
            "version": 8,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 5120,
            "allocation": 94392803166208,
            "allocation_offset": 0
        },
        "t-243": {
            "name": "t-243",
            "dtype": "FP32",
            "shape": [
                10,
                128
            ],
            "strides": [
                128,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 5120,
            "allocation": 94392863192064,
            "allocation_offset": 0
        },
        "t-242": {
            "name": "t-242",
            "dtype": "FP64",
            "shape": [],
            "strides": [],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 8,
            "allocation": 94392863722496,
            "allocation_offset": 0
        },
        "t-244": {
            "name": "t-244",
            "dtype": "FP32",
            "shape": [
                10,
                128
            ],
            "strides": [
                128,
                1
            ],
            "version": 1,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 5120,
            "allocation": 94392863192064,
            "allocation_offset": 0
        },
        "t-247": {
            "name": "t-247",
            "dtype": "FP32",
            "shape": [
                10,
                128
            ],
            "strides": [
                128,
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 5120,
            "allocation": 94392863186944,
            "allocation_offset": 0
        },
        "t-246": {
            "name": "t-246",
            "dtype": "FP32",
            "shape": [
                10,
                128
            ],
            "strides": [
                128,
                1
            ],
            "version": 6,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 5120,
            "allocation": 94392862763008,
            "allocation_offset": 0
        },
        "t-248": {
            "name": "t-248",
            "dtype": "FP32",
            "shape": [
                10,
                128
            ],
            "strides": [
                128,
                1
            ],
            "version": 1,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 5120,
            "allocation": 94392863186944,
            "allocation_offset": 0
        },
        "t-249": {
            "name": "t-249",
            "dtype": "FP32",
            "shape": [
                10,
                128
            ],
            "strides": [
                128,
                1
            ],
            "version": 2,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 5120,
            "allocation": 94392863186944,
            "allocation_offset": 0
        },
        "t-250": {
            "name": "t-250",
            "dtype": "FP32",
            "shape": [
                10,
                128
            ],
            "strides": [
                128,
                1
            ],
            "version": 3,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 5120,
            "allocation": 94392863186944,
            "allocation_offset": 0
        },
        "t-251": {
            "name": "t-251",
            "dtype": "FP32",
            "shape": [
                10,
                128
            ],
            "strides": [
                128,
                1
            ],
            "version": 5,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 5120,
            "allocation": 94392817534976,
            "allocation_offset": 0
        },
        "t-254": {
            "name": "t-254",
            "dtype": "FP32",
            "shape": [
                10,
                128
            ],
            "strides": [
                128,
                1
            ],
            "version": 7,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 5120,
            "allocation": 94392862763008,
            "allocation_offset": 0
        },
        "t-253": {
            "name": "t-253",
            "dtype": "FP64",
            "shape": [],
            "strides": [],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 8,
            "allocation": 94392863724736,
            "allocation_offset": 0
        },
        "t-255": {
            "name": "t-255",
            "dtype": "FP32",
            "shape": [
                10,
                128
            ],
            "strides": [
                128,
                1
            ],
            "version": 8,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 5120,
            "allocation": 94392862763008,
            "allocation_offset": 0
        },
        "t-260": {
            "name": "t-260",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "strides": [
                1
            ],
            "version": 7,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 40,
            "allocation": 94392802021376,
            "allocation_offset": 0
        },
        "t-257": {
            "name": "t-257",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "strides": [
                1
            ],
            "version": 6,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 40,
            "allocation": 94392802021376,
            "allocation_offset": 0
        },
        "t-259": {
            "name": "t-259",
            "dtype": "FP64",
            "shape": [],
            "strides": [],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 8,
            "allocation": 94392863724736,
            "allocation_offset": 0
        },
        "t-261": {
            "name": "t-261",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "strides": [
                1
            ],
            "version": 8,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 40,
            "allocation": 94392802021376,
            "allocation_offset": 0
        },
        "t-264": {
            "name": "t-264",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "strides": [
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 40,
            "allocation": 94392863726080,
            "allocation_offset": 0
        },
        "t-263": {
            "name": "t-263",
            "dtype": "FP64",
            "shape": [],
            "strides": [],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 8,
            "allocation": 94392863724736,
            "allocation_offset": 0
        },
        "t-265": {
            "name": "t-265",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "strides": [
                1
            ],
            "version": 1,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 40,
            "allocation": 94392863726080,
            "allocation_offset": 0
        },
        "t-268": {
            "name": "t-268",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "strides": [
                1
            ],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 40,
            "allocation": 94392863726656,
            "allocation_offset": 0
        },
        "t-267": {
            "name": "t-267",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "strides": [
                1
            ],
            "version": 6,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 40,
            "allocation": 94392802021952,
            "allocation_offset": 0
        },
        "t-269": {
            "name": "t-269",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "strides": [
                1
            ],
            "version": 1,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 40,
            "allocation": 94392863726656,
            "allocation_offset": 0
        },
        "t-270": {
            "name": "t-270",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "strides": [
                1
            ],
            "version": 2,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 40,
            "allocation": 94392863726656,
            "allocation_offset": 0
        },
        "t-271": {
            "name": "t-271",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "strides": [
                1
            ],
            "version": 3,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 40,
            "allocation": 94392863726656,
            "allocation_offset": 0
        },
        "t-272": {
            "name": "t-272",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "strides": [
                1
            ],
            "version": 5,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 40,
            "allocation": 94392802019968,
            "allocation_offset": 0
        },
        "t-275": {
            "name": "t-275",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "strides": [
                1
            ],
            "version": 7,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 40,
            "allocation": 94392802021952,
            "allocation_offset": 0
        },
        "t-274": {
            "name": "t-274",
            "dtype": "FP64",
            "shape": [],
            "strides": [],
            "version": 0,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 8,
            "allocation": 94392863727104,
            "allocation_offset": 0
        },
        "t-276": {
            "name": "t-276",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "strides": [
                1
            ],
            "version": 8,
            "meta": {},
            "const": false,
            "view": null,
            "nbytes": 40,
            "allocation": 94392802021952,
            "allocation_offset": 0
        }
    },
    "inputs": [
        "t-2",
        "t-4",
        "t-6",
        "t-10",
        "t-12",
        "t-19",
        "t-21",
        "t-26",
        "t-28",
        "t-32",
        "t-36",
        "t-39",
        "t-42",
        "t-51",
        "t-55",
        "t-58",
        "t-61",
        "t-64",
        "t-73",
        "t-77",
        "t-81",
        "t-84",
        "t-91",
        "t-94",
        "t-97",
        "t-102",
        "t-105",
        "t-110",
        "t-114",
        "t-118",
        "t-120",
        "t-127",
        "t-131",
        "t-133",
        "t-137",
        "t-141",
        "t-148",
        "t-152",
        "t-154",
        "t-158",
        "t-162",
        "t-169",
        "t-173",
        "t-175",
        "t-179",
        "t-183",
        "t-190",
        "t-194",
        "t-196",
        "t-200",
        "t-204",
        "t-211",
        "t-215",
        "t-217",
        "t-221",
        "t-225",
        "t-232",
        "t-236",
        "t-238",
        "t-242",
        "t-246",
        "t-253",
        "t-257",
        "t-259",
        "t-263",
        "t-267",
        "t-274"
    ],
    "outputs": []
}